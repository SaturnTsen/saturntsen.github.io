import{_ as t,c as n,a as i,o as a}from"./app-BPmJL-vo.js";const o="/images/um-cv-2/16-1.png",s="/images/um-cv-2/16-2.png",r="/images/um-cv-2/16-3.png",c="/images/um-cv-2/16-4.png",p="/images/um-cv-2/16-5.png",l="/images/um-cv-2/16-6.png",m="/images/um-cv-2/16-7.png",g="/images/um-cv-2/16-8.png",d="/images/um-cv-2/16-9.png",h="/images/um-cv-2/16-10.png",u="/images/um-cv-2/16-11.png",b="/images/um-cv-2/16-12.png",f={};function v(y,e){return a(),n("div",null,[...e[0]||(e[0]=[i('<h2 id="summary" tabindex="-1"><a class="header-anchor" href="#summary"><span>Summary</span></a></h2><p>Many Computer Vision Tasks: Classification, Semantic Segmentation, Object Detection, Instance Segmentation, Key Point Estimation, Dense Captioning, etc.</p><p>@Credits: <a href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/" target="_blank" rel="noopener noreferrer">EECS 498.007</a> | Video Lecture: <a href="https://www.youtube.com/watch?v=dJYGatp4SvA&amp;list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r" target="_blank" rel="noopener noreferrer">UM-CV</a></p><p>Personal work for the assignments of the course: <a href="https://github.com/SaturnTsen/EECS-498-007/" target="_blank" rel="noopener noreferrer">github repo</a>.</p><p><strong>Notice on Usage and Attribution</strong></p><p>These are personal class notes based on the University of Michigan EECS 498.008 / 598.008 course. They are intended solely for personal learning and academic discussion, with no commercial use.</p><p>For detailed information, please refer to the <strong><a href="#notice-on-usage-and-attribution">complete notice at the end of this document</a></strong></p><h2 id="object-segmentation" tabindex="-1"><a class="header-anchor" href="#object-segmentation"><span>Object Segmentation</span></a></h2><p>Label each pixel in an image with a category label. Do not differentiate instances, only care about pixels.</p><p>Intuition: Sliding window classifier, but for each pixel.</p><h3 id="fully-convolutional-networks-fcns" tabindex="-1"><a class="header-anchor" href="#fully-convolutional-networks-fcns"><span>Fully Convolutional Networks (FCNs)</span></a></h3><p>The size of the output is the same as the input. Make predictions for pixels all at once!</p><div style="text-align:center;margin-bottom:1em;"><img src="'+o+'" width="60%" alt="FCNs"><br> Fig: FCNs </div><p><a href="https://arxiv.org/abs/1411.4038" target="_blank" rel="noopener noreferrer">Long et al. 2015</a> proposed FCNs for semantic Segmentation</p><p><strong>Problems</strong></p><ol><li>Effective receptive field size is linear in number of conv layers: With L 3x3 conv layers, the receptive field is 1+2L</li><li>Convolution on high res images is expensive</li></ol><p>With down sampling and upsampling inside the network.</p><p><a href="https://arxiv.org/abs/1505.04366" target="_blank" rel="noopener noreferrer">Noh et al, Learning Deconvolution Network for Semantic Segmentation&quot;</a></p><h3 id="unpooling" tabindex="-1"><a class="header-anchor" href="#unpooling"><span>Unpooling</span></a></h3><p>Bed of Nails,KNN, Bilinear Interpolation</p><div style="text-align:center;margin-bottom:1em;"><img src="'+s+'" width="60%" alt="Unpooling"><br> Fig: Unpooling </div><p>Cubic Interpolation, Bicubic Interpolation (两次立方)</p><div style="text-align:center;margin-bottom:1em;"><img src="'+r+'" width="60%" alt="Cubic Interpolation"><br> Fig: Cubic Interpolation </div><div style="text-align:center;margin-bottom:1em;"><img src="'+c+'" width="40%" alt="Bicubic Interpolation"><br> Fig: Bicubic Interpolation </div><p>Max Unpooling: Remember the location of the max value in the pooling layer and put it back in the unpooling layer.</p><p><a href="https://arxiv.org/abs/1505.04366" target="_blank" rel="noopener noreferrer">Noh et al, Learning Deconvolution Network for Semantic Segmentation</a></p><div style="text-align:center;margin-bottom:1em;"><img src="'+p+'" width="60%" alt="Max Unpooling"><br> Fig: Max Unpooling </div><p>Pair each downsampling layer with an upsampling layer.</p><h3 id="transposed-convolution-deconvolution" tabindex="-1"><a class="header-anchor" href="#transposed-convolution-deconvolution"><span>Transposed Convolution (Deconvolution)</span></a></h3><p>Idea: Convolution with stride &gt; 1 is &quot;learnable downsampling&quot;, can we use stride &lt; 1 for &quot;learnable upsampling&quot;?</p><div style="text-align:center;margin-bottom:1em;"><img src="'+l+'" width="40%" alt="Transposed Convolution"><br> Fig: Transposed Convolution </div><div style="text-align:center;margin-bottom:1em;"><img src="'+m+'" width="60%" alt="Transposed Convolution"><br> Fig: Transposed Convolution </div><h2 id="instance-segmentation" tabindex="-1"><a class="header-anchor" href="#instance-segmentation"><span>Instance Segmentation</span></a></h2><p>Semantic segmentation merges objects of the same class.</p><p>Things and stuff: Things are object categories that can be separated into object instances, while stuff is object categories that cannot be separated into object instances.(e.g. sky, grass)</p><p>Object Detection: Detects individual object instances, but only gives box (Only things!)</p><p>Semantic Segmentation: Gives per-pixel labels that does not differentiate between instances.</p><p>Instance Segmentation: Detect all objects in the image and identify the pixels that belong to each object.</p><p>Approach: Perform object detection, then predict a segmentation mask for each object.</p><h3 id="mask-r-cnn" tabindex="-1"><a class="header-anchor" href="#mask-r-cnn"><span>Mask R-CNN</span></a></h3><div style="text-align:center;margin-bottom:1em;"><img src="'+g+'" width="70%" alt="Mask R-CNN"><br> Fig: Mask R-CNN </div><p><a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="noopener noreferrer">ICCV 2017</a></p><ol><li>Region Proposal Network (RPN): Predicts bounding boxes</li><li>Semantic Segmentation for each bounding boxes</li></ol><div style="text-align:center;margin-bottom:1em;"><img src="'+d+'" width="70%" alt="Example Targets"><br> Fig: Example Targets </div><h2 id="panoptic-segmentation" tabindex="-1"><a class="header-anchor" href="#panoptic-segmentation"><span>Panoptic Segmentation</span></a></h2><p>Panoptic 中文的意思是全景，全视角的意思。</p><p>Label all pixels in the image, and for thing categories, differentiate between instances.</p><div style="text-align:center;margin-bottom:1em;"><img src="'+h+'" width="70%" alt="Panoptic Segmentation"><br> Fig: Panoptic Segmentation </div><p><a href="https://arxiv.org/abs/1901.02446" target="_blank" rel="noopener noreferrer">CVPR 2019: Panoptic Feature Pyramid Networks</a></p><h2 id="beyond-instance-segmentation" tabindex="-1"><a class="header-anchor" href="#beyond-instance-segmentation"><span>Beyond Instance Segmentation</span></a></h2><h3 id="key-point-estimation" tabindex="-1"><a class="header-anchor" href="#key-point-estimation"><span>Key Point Estimation</span></a></h3><p>Predict the location of key points on an object.</p><div style="text-align:center;margin-bottom:1em;"><img src="'+u+'" width="70%" alt="Key Point Estimation"><br> Fig: Key Point Estimation </div><p>Mask R-CNN: key points</p><ul><li>Add a keypoint head to predict the location of key points</li></ul><div style="text-align:center;margin-bottom:1em;"><img src="'+b+'" width="70%" alt="Mask R-CNN Key points"><br> Fig: Mask R-CNN Key points </div><p>Joint Instance Segmentation and Keypoint (Pose) Estimation</p><p>General Idea: Add Per-region &quot;Heads&quot; to Faster/ Mask R-CNN!</p><h3 id="dense-captioning" tabindex="-1"><a class="header-anchor" href="#dense-captioning"><span>Dense Captioning</span></a></h3><p><a href="https://arxiv.org/abs/1511.07571" target="_blank" rel="noopener noreferrer">CVPR 2017: DenseCap</a></p><h3 id="_3d-shape-prediction-mask-r-cnn-mesh-head" tabindex="-1"><a class="header-anchor" href="#_3d-shape-prediction-mask-r-cnn-mesh-head"><span>3D Shape Prediction: Mask R-CNN + Mesh Head</span></a></h3><h2 id="notice-on-usage-and-attribution" tabindex="-1"><a class="header-anchor" href="#notice-on-usage-and-attribution"><span><strong>Notice on Usage and Attribution</strong></span></a></h2><p>This note is based on the <strong>University of Michigan&#39;s publicly available course EECS 498.008 / 598.008</strong> and is intended <strong>solely for personal learning and academic discussion</strong>, with no commercial use.</p><ul><li><strong>Nature of the Notes:</strong> These notes include extensive references and citations from course materials to ensure clarity and completeness. However, they are presented as personal interpretations and summaries, not as substitutes for the original course content.</li><li><strong>Original Course Resources:</strong> Please refer to the official <a href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/" target="_blank" rel="noopener noreferrer"><strong>University of Michigan website</strong></a> for complete and accurate course materials.</li><li><strong>Third-Party Open Access Content:</strong> This note may reference Open Access (OA) papers or resources cited within the course materials. These materials are used under their original Open Access licenses (e.g., CC BY, CC BY-SA).</li><li><strong>Proper Attribution:</strong> Every referenced OA resource is appropriately cited, including the author, publication title, source link, and license type.</li><li><strong>Copyright Notice:</strong> All rights to third-party content remain with their respective authors or publishers.</li><li><strong>Content Removal:</strong> If you believe any content infringes on your copyright, please contact me, and I will promptly remove the content in question.</li></ul><p>Thanks to the <strong>University of Michigan</strong> and the contributors to the course for their openness and dedication to accessible education.</p>',65)])])}const S=t(f,[["render",v]]),x=JSON.parse('{"path":"/notes/um-cv/um-cv-16/","title":"16 Object Semantic Segmentation","lang":"en-US","frontmatter":{"title":"16 Object Semantic Segmentation","tags":["computer-vision"],"createTime":"2024/12/29 11:01:56","permalink":"/notes/um-cv/um-cv-16/","outline":[2,4],"description":"Summary Many Computer Vision Tasks: Classification, Semantic Segmentation, Object Detection, Instance Segmentation, Key Point Estimation, Dense Captioning, etc. @Credits: EECS 4...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"16 Object Semantic Segmentation\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-02-21T17:44:17.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://saturntsen.github.io/notes/um-cv/um-cv-16/"}],["meta",{"property":"og:site_name","content":"SaturnTsen"}],["meta",{"property":"og:title","content":"16 Object Semantic Segmentation"}],["meta",{"property":"og:description","content":"Summary Many Computer Vision Tasks: Classification, Semantic Segmentation, Object Detection, Instance Segmentation, Key Point Estimation, Dense Captioning, etc. @Credits: EECS 4..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-02-21T17:44:17.000Z"}],["meta",{"property":"article:tag","content":"computer-vision"}],["meta",{"property":"article:modified_time","content":"2025-02-21T17:44:17.000Z"}]]},"readingTime":{"minutes":3.47,"words":1042},"git":{"createdTime":1735477870000,"updatedTime":1740159857000,"contributors":[{"name":"SaturnTsen","username":"SaturnTsen","email":"minger233@outlook.com","commits":5,"avatar":"https://avatars.githubusercontent.com/SaturnTsen?v=4","url":"https://github.com/SaturnTsen"}]},"autoDesc":true,"filePathRelative":"notes/UM-CV/UM-CV 16 Object Segmentation.md","headers":[],"categoryList":[{"id":"4358b5","sort":10000,"name":"notes"},{"id":"31a781","sort":10004,"name":"UM-CV"}]}');export{S as comp,x as data};
