<!doctype html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.24" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.161" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"15 Object Detection","image":[""],"dateModified":"2025-02-21T17:44:17.000Z","author":[]}</script><meta property="og:url" content="https://saturntsen.github.io/notes/um-cv/um-cv-15/"><meta property="og:site_name" content="SaturnTsen"><meta property="og:title" content="15 Object Detection"><meta property="og:description" content="Summary Slow R-CNN, Fast R-CNN, Faster R-CNN, Single-Stage Object Detection, and their comparison. @Credits: EECS 498.007 | Video Lecture: UM-CV Personal work for the assignment..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-02-21T17:44:17.000Z"><meta property="article:tag" content="computer-vision"><meta property="article:modified_time" content="2025-02-21T17:44:17.000Z"><link rel="icon" href="/favicon.ico"><title>15 Object Detection | SaturnTsen</title><meta name="description" content="Summary Slow R-CNN, Fast R-CNN, Faster R-CNN, Single-Stage Object Detection, and their comparison. @Credits: EECS 498.007 | Video Lecture: UM-CV Personal work for the assignment..."><link rel="preload" href="/assets/style-CU0EtsvZ.css" as="style"><link rel="stylesheet" href="/assets/style-CU0EtsvZ.css"><link rel="modulepreload" href="/assets/app-BPmJL-vo.js"><link rel="modulepreload" href="/assets/index.html-83zXgr4a.js"><link rel="prefetch" href="/assets/index.html-BmG4TjtM.js" as="script"><link rel="prefetch" href="/assets/index.html-BQ1NaJuK.js" as="script"><link rel="prefetch" href="/assets/index.html-vVZNyw0-.js" as="script"><link rel="prefetch" href="/assets/index.html-ZDreb-Cr.js" as="script"><link rel="prefetch" href="/assets/index.html-DnwmR40J.js" as="script"><link rel="prefetch" href="/assets/index.html-DqKRuwzh.js" as="script"><link rel="prefetch" href="/assets/index.html-BnO6pfWi.js" as="script"><link rel="prefetch" href="/assets/index.html-DqrV2oWi.js" as="script"><link rel="prefetch" href="/assets/index.html-D0505yVi.js" as="script"><link rel="prefetch" href="/assets/index.html-D4PfOoAo.js" as="script"><link rel="prefetch" href="/assets/index.html-OZtXDBX-.js" as="script"><link rel="prefetch" href="/assets/index.html-DB8OfTW0.js" as="script"><link rel="prefetch" href="/assets/index.html-Bf7LPeAD.js" as="script"><link rel="prefetch" href="/assets/index.html-Cf43ABLN.js" as="script"><link rel="prefetch" href="/assets/index.html-Dwovho6D.js" as="script"><link rel="prefetch" href="/assets/index.html-BLtwLLZI.js" as="script"><link rel="prefetch" href="/assets/index.html-BUZheLiL.js" as="script"><link rel="prefetch" href="/assets/index.html-DnU5krJy.js" as="script"><link rel="prefetch" href="/assets/index.html-YZrr0wBf.js" as="script"><link rel="prefetch" href="/assets/index.html-bkdbp8wU.js" as="script"><link rel="prefetch" href="/assets/index.html-CWFawhma.js" as="script"><link rel="prefetch" href="/assets/index.html-DGAYbThF.js" as="script"><link rel="prefetch" href="/assets/index.html-C46ohglK.js" as="script"><link rel="prefetch" href="/assets/index.html-CSRYllLl.js" as="script"><link rel="prefetch" href="/assets/index.html-Cnmy6xJA.js" as="script"><link rel="prefetch" href="/assets/index.html-KI14JA6V.js" as="script"><link rel="prefetch" href="/assets/index.html-CFqE0fIB.js" as="script"><link rel="prefetch" href="/assets/index.html-Cp3T_Wdm.js" as="script"><link rel="prefetch" href="/assets/index.html-C5T_LiKK.js" as="script"><link rel="prefetch" href="/assets/index.html-RGl9jofY.js" as="script"><link rel="prefetch" href="/assets/index.html-C2o8eR02.js" as="script"><link rel="prefetch" href="/assets/index.html-C4s21r8r.js" as="script"><link rel="prefetch" href="/assets/index.html-BGMJZV3q.js" as="script"><link rel="prefetch" href="/assets/index.html-BnGAEkBd.js" as="script"><link rel="prefetch" href="/assets/index.html-f3JN0p-H.js" as="script"><link rel="prefetch" href="/assets/index.html-D3JrJcoe.js" as="script"><link rel="prefetch" href="/assets/index.html-DZjtQU4g.js" as="script"><link rel="prefetch" href="/assets/index.html-DPDml381.js" as="script"><link rel="prefetch" href="/assets/index.html-D-DIxWNy.js" as="script"><link rel="prefetch" href="/assets/index.html-M3FNVy5f.js" as="script"><link rel="prefetch" href="/assets/index.html-BxBVeWuK.js" as="script"><link rel="prefetch" href="/assets/index.html-pBhdW37w.js" as="script"><link rel="prefetch" href="/assets/index.html-CMGEEupf.js" as="script"><link rel="prefetch" href="/assets/index.html-XKTeTmUn.js" as="script"><link rel="prefetch" href="/assets/index.html-Nwfmu88j.js" as="script"><link rel="prefetch" href="/assets/index.html-DzKok2JV.js" as="script"><link rel="prefetch" href="/assets/index.html-CzQ1v4M_.js" as="script"><link rel="prefetch" href="/assets/index.html-b5bM2Mm0.js" as="script"><link rel="prefetch" href="/assets/index.html-4FD4vMR_.js" as="script"><link rel="prefetch" href="/assets/index.html-CELX4Gv6.js" as="script"><link rel="prefetch" href="/assets/index.html-DAuv_XsY.js" as="script"><link rel="prefetch" href="/assets/index.html-D0HnbJld.js" as="script"><link rel="prefetch" href="/assets/index.html-cizS7tpp.js" as="script"><link rel="prefetch" href="/assets/index.html-Db9qbygp.js" as="script"><link rel="prefetch" href="/assets/index.html-BC33mLRG.js" as="script"><link rel="prefetch" href="/assets/index.html-Bgjlk9gZ.js" as="script"><link rel="prefetch" href="/assets/index.html-DNyhKRbF.js" as="script"><link rel="prefetch" href="/assets/index.html-MHkPnQ_o.js" as="script"><link rel="prefetch" href="/assets/index.html-gtR08_vy.js" as="script"><link rel="prefetch" href="/assets/index.html-CoqucIIR.js" as="script"><link rel="prefetch" href="/assets/index.html-B6BIthZU.js" as="script"><link rel="prefetch" href="/assets/index.html-BKoKQbyt.js" as="script"><link rel="prefetch" href="/assets/index.html-Bshhoiba.js" as="script"><link rel="prefetch" href="/assets/index.html-nu7-Thlm.js" as="script"><link rel="prefetch" href="/assets/index.html-B1_Iy3K7.js" as="script"><link rel="prefetch" href="/assets/index.html-C5N22UG4.js" as="script"><link rel="prefetch" href="/assets/index.html-C2esroDP.js" as="script"><link rel="prefetch" href="/assets/index.html-BwFyN5XX.js" as="script"><link rel="prefetch" href="/assets/index.html-Cr91GHno.js" as="script"><link rel="prefetch" href="/assets/index.html-D6YLzvpj.js" as="script"><link rel="prefetch" href="/assets/index.html-Ds6znEeN.js" as="script"><link rel="prefetch" href="/assets/index.html-CAJn5R2r.js" as="script"><link rel="prefetch" href="/assets/index.html-CfYOQ07j.js" as="script"><link rel="prefetch" href="/assets/index.html-BpdD7CET.js" as="script"><link rel="prefetch" href="/assets/404.html-BRfb-qcV.js" as="script"><link rel="prefetch" href="/assets/index.html-DN0XcQYf.js" as="script"><link rel="prefetch" href="/assets/index.html-BrfGEaVq.js" as="script"><link rel="prefetch" href="/assets/index.html-DPdADZ69.js" as="script"><link rel="prefetch" href="/assets/index.html-Cxk-aAuN.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/giscus-BACEvYzX.js" as="script"><link rel="prefetch" href="/assets/searchBox-default-BgWbHU8C.js" as="script"><link rel="prefetch" href="/assets/SearchBox-D0_iY6j8.js" as="script"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-a218b6db><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-7a21891b></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-7a21891b> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-a218b6db data-v-cfd3cabe><div class="vp-navbar" vp-navbar data-v-cfd3cabe data-v-f0d7e165><div class="wrapper" data-v-f0d7e165><div class="container" data-v-f0d7e165><div class="title" data-v-f0d7e165><div class="vp-navbar-title has-sidebar" data-v-f0d7e165 data-v-78317e40><a class="vp-link link no-icon title" href="/" data-v-78317e40><!--[--><!--[--><!--]--><!--[--><!--[--><!--[--><img class="vp-image dark logo" style="" src="/avatars/avatar.png" alt data-v-17210522><!--]--><!--[--><img class="vp-image light logo" style="" src="/avatars/avatar.png" alt data-v-17210522><!--]--><!--]--><!--]--><span data-v-78317e40>SaturnTsen</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-f0d7e165><div class="content-body" data-v-f0d7e165><!--[--><!--]--><div class="vp-navbar-search search" data-v-f0d7e165><div class="search-wrapper" data-v-895d8b33><!----><div id="local-search" data-v-895d8b33><button type="button" class="mini-search mini-search-button" aria-label="Search" data-v-895d8b33><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">Search</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><!--[--><!--]--><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-f0d7e165 data-v-dd33332d><span id="main-nav-aria-label" class="visually-hidden" data-v-dd33332d>Main Navigation</span><!--[--><!--[--><a class="vp-link link navbar-menu-link" href="/" tabindex="0" data-v-dd33332d data-v-caac0954><!--[--><!----><span data-v-caac0954>Home</span><!----><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-dd33332d data-v-3dde86b7><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-3dde86b7><span class="text" data-v-3dde86b7><!----><!----><span data-v-3dde86b7>Notes</span><!----><span class="vpi-chevron-down text-icon" data-v-3dde86b7></span></span></button><div class="menu" data-v-3dde86b7><div class="vp-menu" data-v-3dde86b7 data-v-55c02a15><div class="items" data-v-55c02a15><!--[--><!--[--><div class="vp-menu-link" data-v-55c02a15 data-v-b7034f0e><a class="vp-link link" href="/notes/um-cv/" data-v-b7034f0e><!--[--><!----> CV-NNDL <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-55c02a15 data-v-b7034f0e><a class="vp-link link" href="/notes/leetcode/" data-v-b7034f0e><!--[--><!----> LeetCode <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-55c02a15 data-v-b7034f0e><a class="vp-link link" href="/notes/misc/" data-v-b7034f0e><!--[--><!----> Misc <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!--[--><!--]--><!----><div class="vp-navbar-appearance appearance" data-v-f0d7e165 data-v-be794682><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-be794682 data-v-42684fe4 data-v-196dff46><span class="check" data-v-196dff46><span class="icon" data-v-196dff46><!--[--><span class="vpi-sun sun" data-v-42684fe4></span><span class="vpi-moon moon" data-v-42684fe4></span><!--]--></span></span></button></div><div class="vp-social-links vp-navbar-social-links social-links" data-v-f0d7e165 data-v-a8dae519 data-v-865113bf><!--[--><a class="vp-social-link no-icon" href="https://github.com/saturntsen" aria-label="github" target="_blank" rel="noopener" data-v-865113bf data-v-08f84eea><span class="vpi-social-github" /></a><!--]--></div><div class="vp-flyout vp-navbar-extra extra" data-v-f0d7e165 data-v-59aeafe8 data-v-3dde86b7><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-3dde86b7><span class="vpi-more-horizontal icon" data-v-3dde86b7></span></button><div class="menu" data-v-3dde86b7><div class="vp-menu" data-v-3dde86b7 data-v-55c02a15><!----><!--[--><!--[--><!----><div class="group" data-v-59aeafe8><div class="item appearance" data-v-59aeafe8><p class="label" data-v-59aeafe8>Appearance</p><div class="appearance-action" data-v-59aeafe8><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-59aeafe8 data-v-42684fe4 data-v-196dff46><span class="check" data-v-196dff46><span class="icon" data-v-196dff46><!--[--><span class="vpi-sun sun" data-v-42684fe4></span><span class="vpi-moon moon" data-v-42684fe4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-59aeafe8><div class="item social-links" data-v-59aeafe8><div class="vp-social-links social-links-list" data-v-59aeafe8 data-v-865113bf><!--[--><a class="vp-social-link no-icon" href="https://github.com/saturntsen" aria-label="github" target="_blank" rel="noopener" data-v-865113bf data-v-08f84eea><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-f0d7e165 data-v-c65a6891><span class="container" data-v-c65a6891><span class="top" data-v-c65a6891></span><span class="middle" data-v-c65a6891></span><span class="bottom" data-v-c65a6891></span></span></button></div></div></div></div><div class="divider" data-v-f0d7e165><div class="divider-line" data-v-f0d7e165></div></div></div><!----></header><div class="vp-local-nav reached-top" data-v-a218b6db data-v-e2935d30><button class="menu" aria-expanded="false" aria-controls="SidebarNav" data-v-e2935d30><span class="vpi-align-left menu-icon" data-v-e2935d30></span><span class="menu-text" data-v-e2935d30>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-e2935d30 data-v-ff10071c><button data-v-ff10071c>Return to top</button><!----></div></div><aside class="vp-sidebar" vp-sidebar data-v-a218b6db data-v-4f040617><div class="curtain" data-v-4f040617></div><nav id="SidebarNav" class="nav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-4f040617><span id="sidebar-aria-label" class="visually-hidden" data-v-4f040617> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-80522f8e><section class="vp-sidebar-item sidebar-item level-0 has-active" data-v-80522f8e data-v-467b1cf7><div class="item" role="button" tabindex="0" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><h2 class="text" data-v-467b1cf7><span data-v-467b1cf7>UM-CV</span><!----></h2><!----></div><div data-v-467b1cf7 data-v-467b1cf7><div class="items" data-v-467b1cf7><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>README</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-1/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>1 Intro</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-2/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>2 Image Classification</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-3-4/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>3 & 4 Linear Classifiers and Optimization</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-5/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>5 & 6 Neural Networks and Back Propagation</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/backprop-calc-1/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>Two-layer MLP backprop</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/backprop-calc-2/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>Batch Normalization backprop</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-7/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>7 & 8 CNN and its design principles</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-9/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>9 Hardware, Software, PyTorch Modules</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-10/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>10 & 11 Training Neural Networks</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-12/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>12 & 13 Recurrent Neural Networks & Attention Mechanism</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-14/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>14 Visualizing and understanding CNNs</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-15/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>15 Object Detection</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-16/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>16 Object Semantic Segmentation</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-17/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>17 3D Vision</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-18/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>18 Videos</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-19/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>19 Autoregressive Models, Variational Autoencoders</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-20/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>20 Generative Adversarial Networks</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-21/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>21 Reinforcement Learning</span><!----></p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><!--]--><!--[--><!--]--></nav></aside><!--[--><div id="VPContent" vp-content class="vp-content has-sidebar" data-v-a218b6db data-v-6e8aa8db><div class="vp-doc-container has-sidebar has-aside" data-v-6e8aa8db data-v-380c246c><!--[--><!--]--><div class="container" data-v-380c246c><div class="aside" vp-outline data-v-380c246c><div class="aside-curtain" data-v-380c246c></div><div class="aside-container" data-v-380c246c><div class="aside-content" data-v-380c246c><div class="vp-doc-aside" data-v-380c246c data-v-36d29b94><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="vp-doc-aside-outline" role="navigation" data-v-36d29b94 data-v-924d914c><div class="content" data-v-924d914c><div class="outline-marker" data-v-924d914c></div><div id="doc-outline-aria-label" aria-level="2" class="outline-title" role="heading" data-v-924d914c><span data-v-924d914c>On this page</span><span class="vpi-print icon" data-v-924d914c></span></div><ul class="root" data-v-924d914c data-v-fc78de7f><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-36d29b94></div><!--[--><!--]--></div></div></div></div><div class="content" data-v-380c246c><div class="content-container" data-v-380c246c><!--[--><!--]--><main class="main" data-v-380c246c><nav class="vp-breadcrumb" data-v-380c246c data-v-389ad6f0><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-389ad6f0><!--[--><li property="itemListElement" typeof="ListItem" data-v-389ad6f0><a class="vp-link link breadcrumb" href="/" property="item" typeof="WebPage" data-v-389ad6f0><!--[-->Home<!--]--><!----></a><span class="vpi-chevron-right" data-v-389ad6f0></span><meta property="name" content="Home" data-v-389ad6f0><meta property="position" content="1" data-v-389ad6f0></li><li property="itemListElement" typeof="ListItem" data-v-389ad6f0><span class="vp-link breadcrumb" property="item" typeof="WebPage" data-v-389ad6f0><!--[-->UM-CV<!--]--><!----></span><span class="vpi-chevron-right" data-v-389ad6f0></span><meta property="name" content="UM-CV" data-v-389ad6f0><meta property="position" content="2" data-v-389ad6f0></li><li property="itemListElement" typeof="ListItem" data-v-389ad6f0><a class="vp-link link breadcrumb current" href="/notes/um-cv/um-cv-15/" property="item" typeof="WebPage" data-v-389ad6f0><!--[-->15 Object Detection<!--]--><!----></a><!----><meta property="name" content="15 Object Detection" data-v-389ad6f0><meta property="position" content="3" data-v-389ad6f0></li><!--]--></ol></nav><!--[--><!--]--><!--[--><h1 class="vp-doc-title page-title" data-v-8dd3566a><!----> 15 Object Detection <!----></h1><div class="vp-doc-meta" data-v-8dd3566a><!--[--><!--]--><p class="reading-time" data-v-8dd3566a><span class="vpi-books icon" data-v-8dd3566a></span><span data-v-8dd3566a>About 1615 words</span><span data-v-8dd3566a>About 5 min</span></p><p data-v-8dd3566a><span class="vpi-tag icon" data-v-8dd3566a></span><!--[--><span class="vp-link tag vp-tag-akhq" data-v-8dd3566a><!--[-->computer-vision<!--]--><!----></span><!--]--></p><!--[--><!--]--><p class="create-time" data-v-8dd3566a><span class="vpi-clock icon" data-v-8dd3566a></span><span data-v-8dd3566a>2024-12-29</span></p></div><!--]--><!--[--><!--]--><div class="_notes_um-cv_um-cv-15_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-380c246c><!--[--><!--]--><div data-v-380c246c><h2 id="summary" tabindex="-1"><a class="header-anchor" href="#summary"><span>Summary</span></a></h2><p>Slow R-CNN, Fast R-CNN, Faster R-CNN, Single-Stage Object Detection, and their comparison.</p><p>@Credits: <a href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/" target="_blank" rel="noopener noreferrer">EECS 498.007</a> | Video Lecture: <a href="https://www.youtube.com/watch?v=dJYGatp4SvA&amp;list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r" target="_blank" rel="noopener noreferrer">UM-CV</a></p><p>Personal work for the assignments of the course: <a href="https://github.com/SaturnTsen/EECS-498-007/" target="_blank" rel="noopener noreferrer">github repo</a>.</p><p><strong>Notice on Usage and Attribution</strong></p><p>These are personal class notes based on the University of Michigan EECS 498.008 / 598.008 course. They are intended solely for personal learning and academic discussion, with no commercial use.</p><p>For detailed information, please refer to the <strong><a href="#notice-on-usage-and-attribution">complete notice at the end of this document</a></strong></p><h2 id="intro" tabindex="-1"><a class="header-anchor" href="#intro"><span>Intro</span></a></h2><h3 id="task-definition" tabindex="-1"><a class="header-anchor" href="#task-definition"><span>Task Definition</span></a></h3><p>Input: Single RGB image Output： A set of detected objects; for each object predict:</p><p>Computer Vision Tasks:Classification, Semantic Segmentation, Object Detection, Instance Segmentation</p><ol><li>Category label (from fixed, known set of categories)</li><li>Bounding box (four numbers, x, y, width, height)</li></ol><h3 id="challenges" tabindex="-1"><a class="header-anchor" href="#challenges"><span>Challenges</span></a></h3><ul><li>Multiple outputs: Need to output variable numbers of objects per image</li><li>Multiple types of output&quot; Need to predict &quot;what&quot; (category label) as well as &quot;where&quot; (bounding box)</li><li>Large images: Classification works at 224 x 224; need higher resolution for detection, often 800 x 800 or more</li><li>Detecting Multiple Objects: Need different numbers of outputs per image</li></ul><h2 id="region-based-cnn-r-cnn" tabindex="-1"><a class="header-anchor" href="#region-based-cnn-r-cnn"><span>Region-based CNN (R-CNN)</span></a></h2><p>CVPR 2014</p><h3 id="window-detection" tabindex="-1"><a class="header-anchor" href="#window-detection"><span>Window Detection</span></a></h3><h4 id="sliding-window" tabindex="-1"><a class="header-anchor" href="#sliding-window"><span>Sliding Window?</span></a></h4><ul><li><p>Apply a cnn to many different crops of the image, CNN classifies each crop as object or background. And enumerate all possible crops -&gt; too slow.</p></li><li><p>Region Proposals: Find a small set of boxes that are likely to cover all objects. Often based on heuristics: e.g. look for &quot;blob-like&quot; image regions. This is relatively fast to run; e.g. Selective Search gives 2000 region proposals in a few seconds on CPU</p></li><li><p>Regions of interest (RoI) from a proposal methods. For each RoI, apply a CNN to predict the class of the object in the RoI and refine the bounding box.</p></li><li><p>Bounding box regression: predict &quot;transform&quot; to correct the RoI: x, y, w, h</p></li></ul><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-1.png" width="70%" alt="Bounding box regression"><br> Fig: Bounding-box regression</div><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-2.png" width="70%" alt="R-CNN"><br> Fig: R-CNN</div><p>During training, backpropagate on all the regions of interest (RoIs).</p><h3 id="comparing-boxes-intersection-over-union-iou" tabindex="-1"><a class="header-anchor" href="#comparing-boxes-intersection-over-union-iou"><span>Comparing Boxes: Intersection over Union (IoU)</span></a></h3><ul><li>IoU = Area of overlap / Area of union. Also called &quot;Jaccard similarity&quot; or &quot;Jaccard index&quot;.</li><li>IoU &gt; 0.5 is &quot;decent&quot;. IoU &gt; 0.7 is &quot;good&quot;. IoU &gt; 0.9 is &quot;almost perfect&quot;.</li></ul><h4 id="overlapping-boxes" tabindex="-1"><a class="header-anchor" href="#overlapping-boxes"><span>Overlapping Boxes</span></a></h4><p>Object detectors often output many overlapping detections. Solution: Post-process raw detections using Non-Max Suppression (NMS).</p><ol><li>Select next highest-scoring box</li><li>Eliminate lower-scoring boxes with IoU &gt; threshold</li></ol><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-3.png" width="70%" alt="Non-Max Suppression"><br> Fig: Non-Max Suppression</div><p>Problem: NMS may eliminate &quot;good&quot; boxes when objects are highly overlapping...</p><h3 id="evaluating-object-detectors-mean-average-precision-map" tabindex="-1"><a class="header-anchor" href="#evaluating-object-detectors-mean-average-precision-map"><span>Evaluating Object Detectors: Mean Average Precision (mAP)</span></a></h3><ol><li>Run object detector on all test images (with NMS)</li><li>For each category, compute average precision (AP) = area under precision vs recall curve</li></ol><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-4.png" width="70%" alt="Mean Average Precision"><br> Fig: Mean Average Precision</div><ol start="3"><li>mean Average Precision (mAP) = mean of AP over all categories</li><li>for &quot;COCO mAP&quot;, average over 10 IoU thresholds (0.5 to 0.95) and take average</li></ol><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-5.png" width="70%" alt="COCO mAP"><br> Fig: COCO mAP</div><h2 id="fast-rcnn" tabindex="-1"><a class="header-anchor" href="#fast-rcnn"><span>Fast-RCNN</span></a></h2><p>ICCV 2015</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-6.png" width="70%" alt="Fast-RCNN"><br> Fig: Fast-RCNN</div><h3 id="crop-features-roi-pool" tabindex="-1"><a class="header-anchor" href="#crop-features-roi-pool"><span>Crop Features: RoI Pool</span></a></h3><p>Input Image: e.g. 3 x 640 x 480 -&gt; CNN (e.g. 512 x 20 x15)</p><p>Project and snap RoI to CNN feature map - &gt; Divide into 2x2 grid of (roughly) equal subregions -&gt; Max pool within each subregion (e.g. 512 x 7 x 7)</p><p>Region features always the same size even if input regions have different sizes!</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-7.png" width="70%" alt="RoI Pool"><br> Fig: RoI Pool</div><p>Problem: Slight misalignment between RoI and CNN grid can cause misalignment in RoI Pooling. Solution: RoI Align</p><h3 id="roi-align" tabindex="-1"><a class="header-anchor" href="#roi-align"><span>RoI Align</span></a></h3><ul><li>Instead of snapping RoI to CNN grid, interpolate between grid points</li><li>More accurate, but more expensive</li></ul><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-8.png" width="70%" alt="RoI Align"><br> Fig: RoI Align</div><p>The cropping may not perfectly match the original object grid. RoI Align implements a bilinear near-neighbor interpolation to get more accurate cropping. We can consider the image as a real-valued tensor and backpropagate to any points in the image.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-16.png" width="70%" alt="RoI Align"><br> Fig: RoI Align</div><h3 id="fast-r-cnn-vs-slow-r-cnn-iccv-2015" tabindex="-1"><a class="header-anchor" href="#fast-r-cnn-vs-slow-r-cnn-iccv-2015"><span>Fast R-CNN vs &quot;Slow&quot; R-CNN (ICCV 2015)</span></a></h3><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-9.png" width="70%" alt="Fast R-CNN"><br> Fig: Fast R-CNN</div><h2 id="faster-r-cnn-learnable-region-proposals" tabindex="-1"><a class="header-anchor" href="#faster-r-cnn-learnable-region-proposals"><span>Faster R-CNN: Learnable Region Proposals</span></a></h2><p>Train a CNN to predict region proposals. NeurIPS 2015</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-10.png" width="70%" alt="Faster R-CNN"><br> Fig: Faster R-CNN</div><p><strong>Region Proposal Network (RPN):</strong></p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-11.png" width="70%" alt="Region Proposal Network"><br> Fig: Region Proposal Network</div><ul><li><p>Anchor box of fixed size at each point in the feature map.</p></li><li><p>At each point, predict whether the corresponding anchor contains an object or not (per-cell logistic regression, predict scores with conv layer.)</p></li><li><p>For positive boxes, also predict a box transform to regress from anchor to object box.</p></li><li><p>Problem: Anchor box may be too small or too large for the object. Solution: K Multi-scale anchors for each point.</p></li></ul><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-12.png" width="70%" alt="Multi-scale anchors"><br> Fig: Multi-scale anchors</div><p>Jointly with 4 losses:</p><ol><li>RPN classification loss: anchor box is object or not</li><li>RPN regression loss: predict transform from anchor box to proposal box</li><li>Object classification: classify proposals as background or object class</li><li>Object regression: predict transform from a proposal box to object box</li></ol><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-13.png" width="50%" alt="Faster R-CNN"><br> Fig: Faster R-CNN</div><p>Two stages:</p><p>First stage: Run once per image</p><ul><li>Backbone Network</li><li>Region proposal network</li></ul><p>Second stage: Run once per region</p><ul><li>Crop features: RoI pool/align</li><li>Predict object class</li><li>Prediction bbox offset</li></ul><h2 id="single-stage-object-detection" tabindex="-1"><a class="header-anchor" href="#single-stage-object-detection"><span>Single-Stage Object Detection</span></a></h2><ul><li>YOLO: You Only Look Once. ECCV 2016</li><li>Focal Loss for Dense Object Detection. ICCV 2017</li></ul><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-14.png" width="70%" alt="YOLO"><br> Fig: YOLO</div><h2 id="detection-without-anchors-cornernet-eccv-2018" tabindex="-1"><a class="header-anchor" href="#detection-without-anchors-cornernet-eccv-2018"><span>Detection without Anchors: CornerNet (ECCV 2018)</span></a></h2><p>Use a backbone CNN to predict the heatmap of object upper-left corners and lower-right corners.</p><p>To match the upper-left and lower-right corners, use a &quot;associative embedding&quot; to predict the offset between the two corners.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-17.png" width="70%" alt="CornerNet"><br> Fig: CornerNet</div><h2 id="comparison" tabindex="-1"><a class="header-anchor" href="#comparison"><span>Comparison</span></a></h2><p><a href="https://arxiv.org/abs/1611.10012" target="_blank" rel="noopener noreferrer">Speed/accuracy trade-offs for modern convolutional object detectors</a> CVPR 2017</p><p>Takeaways:</p><ul><li>Two stage method (e.g. Faster R-CNN) is more accurate but slower</li><li>Single stage methods (e.g. YOLO, SSD) are faster but less accurate</li><li>Bigger backbones improve performance, but are slower</li><li>Nowadays, single stage methods are as good as two-stage methods</li><li>Very big models work better</li><li>Test-time augmentation pushes numbers up</li><li>Big ensembles, more data, etc</li></ul><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv-2/15-15.png" width="70%" alt="Comparison"><br> Fig: Comparison</div><h3 id="object-detection-open-source-code" tabindex="-1"><a class="header-anchor" href="#object-detection-open-source-code"><span>Object Detection: Open-Source Code</span></a></h3><p>Don&#39;t implement it yourself (Unless you are working on the assignment)</p><p><a href="https://github.com/facebookresearch/detectron2" target="_blank" rel="noopener noreferrer">Detectron2 (PyTorch)</a></p><p>Fast/Faster/Mask R-CNN, RetinaNet</p><h2 id="notice-on-usage-and-attribution" tabindex="-1"><a class="header-anchor" href="#notice-on-usage-and-attribution"><span><strong>Notice on Usage and Attribution</strong></span></a></h2><p>This note is based on the <strong>University of Michigan&#39;s publicly available course EECS 498.008 / 598.008</strong> and is intended <strong>solely for personal learning and academic discussion</strong>, with no commercial use.</p><ul><li><strong>Nature of the Notes:</strong> These notes include extensive references and citations from course materials to ensure clarity and completeness. However, they are presented as personal interpretations and summaries, not as substitutes for the original course content.</li><li><strong>Original Course Resources:</strong> Please refer to the official <a href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/" target="_blank" rel="noopener noreferrer"><strong>University of Michigan website</strong></a> for complete and accurate course materials.</li><li><strong>Third-Party Open Access Content:</strong> This note may reference Open Access (OA) papers or resources cited within the course materials. These materials are used under their original Open Access licenses (e.g., CC BY, CC BY-SA).</li><li><strong>Proper Attribution:</strong> Every referenced OA resource is appropriately cited, including the author, publication title, source link, and license type.</li><li><strong>Copyright Notice:</strong> All rights to third-party content remain with their respective authors or publishers.</li><li><strong>Content Removal:</strong> If you believe any content infringes on your copyright, please contact me, and I will promptly remove the content in question.</li></ul><p>Thanks to the <strong>University of Michigan</strong> and the contributors to the course for their openness and dedication to accessible education.</p></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-380c246c data-v-7bfa3324><!--[--><!--]--><div class="edit-info" data-v-7bfa3324><div class="edit-link" data-v-7bfa3324><a class="vp-link link no-icon edit-link-button" href="https://github.com/SaturnTsen/saturntsen.github.io/edit/main/docs/notes/UM-CV/UM-CV 15 Object Detection.md" target="_blank" rel="noreferrer" data-v-7bfa3324><!--[--><span class="vpi-square-pen edit-link-icon" aria-label="edit icon" data-v-7bfa3324></span> Edit this page<!--]--><!----></a></div><!----></div><div class="contributors" aria-label="Contributors" data-v-7bfa3324><span class="contributors-label" data-v-7bfa3324>Contributors: </span><span class="contributors-info" data-v-7bfa3324><!--[--><!--[--><span class="contributor" data-v-7bfa3324>SaturnTsen</span><!----><!--]--><!--]--></span></div><nav class="prev-next" data-v-7bfa3324><div class="pager" data-v-7bfa3324><a class="vp-link link pager-link prev" href="/notes/um-cv/um-cv-14/" data-v-7bfa3324><!--[--><span class="desc" data-v-7bfa3324>Previous page</span><span class="title" data-v-7bfa3324>14 Visualizing and understanding CNNs</span><!--]--><!----></a></div><div class="pager" data-v-7bfa3324><a class="vp-link link pager-link next" href="/notes/um-cv/um-cv-16/" data-v-7bfa3324><!--[--><span class="desc" data-v-7bfa3324>Next page</span><span class="title" data-v-7bfa3324>16 Object Semantic Segmentation</span><!--]--><!----></a></div></nav></footer><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;" data-v-380c246c><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div></div><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-a218b6db data-v-6955073a><span class="percent" data-allow-mismatch data-v-6955073a>0%</span><span class="show icon vpi-back-to-top" data-v-6955073a></span><svg aria-hidden="true" data-v-6955073a><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-6955073a></circle></svg></button><footer class="vp-footer has-sidebar" vp-footer data-v-a218b6db data-v-d9d63044><!--[--><div class="container" data-v-d9d63044><p class="message" data-v-d9d63044>Powered by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://theme-plume.vuejs.press">vuepress-theme-plume</a></p><p class="copyright" data-v-d9d63044>© 2024 SaturnTsen | Powered by <a href="https://vuepress.vuejs.org/" target="_blank">VuePress</a> & <a href="https://theme-plume.vuejs.press/" target="_blank">Plume</a></p></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-BPmJL-vo.js" defer></script></body></html>