<!doctype html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.24" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.161" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"14 Visualizing and understanding CNNs","image":[""],"dateModified":"2025-02-21T17:44:17.000Z","author":[]}</script><meta property="og:url" content="https://saturntsen.github.io/notes/um-cv/um-cv-14/"><meta property="og:site_name" content="SaturnTsen"><meta property="og:title" content="14 Visualizing and understanding CNNs"><meta property="og:description" content="Various techniques to visualize and understand CNNs. Activations: Nearest neighbors, PCA, t-SNE, saliency, occlusion, backpropagation. Gradients: Saliency maps, class visualizat..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-02-21T17:44:17.000Z"><meta property="article:tag" content="computer-vision"><meta property="article:tag" content="notes"><meta property="article:modified_time" content="2025-02-21T17:44:17.000Z"><link rel="icon" href="/favicon.ico"><title>14 Visualizing and understanding CNNs | SaturnTsen</title><meta name="description" content="Various techniques to visualize and understand CNNs. Activations: Nearest neighbors, PCA, t-SNE, saliency, occlusion, backpropagation. Gradients: Saliency maps, class visualizat..."><link rel="preload" href="/assets/style-CU0EtsvZ.css" as="style"><link rel="stylesheet" href="/assets/style-CU0EtsvZ.css"><link rel="modulepreload" href="/assets/app-BPmJL-vo.js"><link rel="modulepreload" href="/assets/index.html-Dwovho6D.js"><link rel="prefetch" href="/assets/index.html-BmG4TjtM.js" as="script"><link rel="prefetch" href="/assets/index.html-BQ1NaJuK.js" as="script"><link rel="prefetch" href="/assets/index.html-vVZNyw0-.js" as="script"><link rel="prefetch" href="/assets/index.html-ZDreb-Cr.js" as="script"><link rel="prefetch" href="/assets/index.html-DnwmR40J.js" as="script"><link rel="prefetch" href="/assets/index.html-DqKRuwzh.js" as="script"><link rel="prefetch" href="/assets/index.html-BnO6pfWi.js" as="script"><link rel="prefetch" href="/assets/index.html-DqrV2oWi.js" as="script"><link rel="prefetch" href="/assets/index.html-D0505yVi.js" as="script"><link rel="prefetch" href="/assets/index.html-D4PfOoAo.js" as="script"><link rel="prefetch" href="/assets/index.html-OZtXDBX-.js" as="script"><link rel="prefetch" href="/assets/index.html-DB8OfTW0.js" as="script"><link rel="prefetch" href="/assets/index.html-Bf7LPeAD.js" as="script"><link rel="prefetch" href="/assets/index.html-Cf43ABLN.js" as="script"><link rel="prefetch" href="/assets/index.html-83zXgr4a.js" as="script"><link rel="prefetch" href="/assets/index.html-BLtwLLZI.js" as="script"><link rel="prefetch" href="/assets/index.html-BUZheLiL.js" as="script"><link rel="prefetch" href="/assets/index.html-DnU5krJy.js" as="script"><link rel="prefetch" href="/assets/index.html-YZrr0wBf.js" as="script"><link rel="prefetch" href="/assets/index.html-bkdbp8wU.js" as="script"><link rel="prefetch" href="/assets/index.html-CWFawhma.js" as="script"><link rel="prefetch" href="/assets/index.html-DGAYbThF.js" as="script"><link rel="prefetch" href="/assets/index.html-C46ohglK.js" as="script"><link rel="prefetch" href="/assets/index.html-CSRYllLl.js" as="script"><link rel="prefetch" href="/assets/index.html-Cnmy6xJA.js" as="script"><link rel="prefetch" href="/assets/index.html-KI14JA6V.js" as="script"><link rel="prefetch" href="/assets/index.html-CFqE0fIB.js" as="script"><link rel="prefetch" href="/assets/index.html-Cp3T_Wdm.js" as="script"><link rel="prefetch" href="/assets/index.html-C5T_LiKK.js" as="script"><link rel="prefetch" href="/assets/index.html-RGl9jofY.js" as="script"><link rel="prefetch" href="/assets/index.html-C2o8eR02.js" as="script"><link rel="prefetch" href="/assets/index.html-C4s21r8r.js" as="script"><link rel="prefetch" href="/assets/index.html-BGMJZV3q.js" as="script"><link rel="prefetch" href="/assets/index.html-BnGAEkBd.js" as="script"><link rel="prefetch" href="/assets/index.html-f3JN0p-H.js" as="script"><link rel="prefetch" href="/assets/index.html-D3JrJcoe.js" as="script"><link rel="prefetch" href="/assets/index.html-DZjtQU4g.js" as="script"><link rel="prefetch" href="/assets/index.html-DPDml381.js" as="script"><link rel="prefetch" href="/assets/index.html-D-DIxWNy.js" as="script"><link rel="prefetch" href="/assets/index.html-M3FNVy5f.js" as="script"><link rel="prefetch" href="/assets/index.html-BxBVeWuK.js" as="script"><link rel="prefetch" href="/assets/index.html-pBhdW37w.js" as="script"><link rel="prefetch" href="/assets/index.html-CMGEEupf.js" as="script"><link rel="prefetch" href="/assets/index.html-XKTeTmUn.js" as="script"><link rel="prefetch" href="/assets/index.html-Nwfmu88j.js" as="script"><link rel="prefetch" href="/assets/index.html-DzKok2JV.js" as="script"><link rel="prefetch" href="/assets/index.html-CzQ1v4M_.js" as="script"><link rel="prefetch" href="/assets/index.html-b5bM2Mm0.js" as="script"><link rel="prefetch" href="/assets/index.html-4FD4vMR_.js" as="script"><link rel="prefetch" href="/assets/index.html-CELX4Gv6.js" as="script"><link rel="prefetch" href="/assets/index.html-DAuv_XsY.js" as="script"><link rel="prefetch" href="/assets/index.html-D0HnbJld.js" as="script"><link rel="prefetch" href="/assets/index.html-cizS7tpp.js" as="script"><link rel="prefetch" href="/assets/index.html-Db9qbygp.js" as="script"><link rel="prefetch" href="/assets/index.html-BC33mLRG.js" as="script"><link rel="prefetch" href="/assets/index.html-Bgjlk9gZ.js" as="script"><link rel="prefetch" href="/assets/index.html-DNyhKRbF.js" as="script"><link rel="prefetch" href="/assets/index.html-MHkPnQ_o.js" as="script"><link rel="prefetch" href="/assets/index.html-gtR08_vy.js" as="script"><link rel="prefetch" href="/assets/index.html-CoqucIIR.js" as="script"><link rel="prefetch" href="/assets/index.html-B6BIthZU.js" as="script"><link rel="prefetch" href="/assets/index.html-BKoKQbyt.js" as="script"><link rel="prefetch" href="/assets/index.html-Bshhoiba.js" as="script"><link rel="prefetch" href="/assets/index.html-nu7-Thlm.js" as="script"><link rel="prefetch" href="/assets/index.html-B1_Iy3K7.js" as="script"><link rel="prefetch" href="/assets/index.html-C5N22UG4.js" as="script"><link rel="prefetch" href="/assets/index.html-C2esroDP.js" as="script"><link rel="prefetch" href="/assets/index.html-BwFyN5XX.js" as="script"><link rel="prefetch" href="/assets/index.html-Cr91GHno.js" as="script"><link rel="prefetch" href="/assets/index.html-D6YLzvpj.js" as="script"><link rel="prefetch" href="/assets/index.html-Ds6znEeN.js" as="script"><link rel="prefetch" href="/assets/index.html-CAJn5R2r.js" as="script"><link rel="prefetch" href="/assets/index.html-CfYOQ07j.js" as="script"><link rel="prefetch" href="/assets/index.html-BpdD7CET.js" as="script"><link rel="prefetch" href="/assets/404.html-BRfb-qcV.js" as="script"><link rel="prefetch" href="/assets/index.html-DN0XcQYf.js" as="script"><link rel="prefetch" href="/assets/index.html-BrfGEaVq.js" as="script"><link rel="prefetch" href="/assets/index.html-DPdADZ69.js" as="script"><link rel="prefetch" href="/assets/index.html-Cxk-aAuN.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/giscus-BACEvYzX.js" as="script"><link rel="prefetch" href="/assets/searchBox-default-BgWbHU8C.js" as="script"><link rel="prefetch" href="/assets/SearchBox-D0_iY6j8.js" as="script"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-a218b6db><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-7a21891b></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-7a21891b> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-a218b6db data-v-cfd3cabe><div class="vp-navbar" vp-navbar data-v-cfd3cabe data-v-f0d7e165><div class="wrapper" data-v-f0d7e165><div class="container" data-v-f0d7e165><div class="title" data-v-f0d7e165><div class="vp-navbar-title has-sidebar" data-v-f0d7e165 data-v-78317e40><a class="vp-link link no-icon title" href="/" data-v-78317e40><!--[--><!--[--><!--]--><!--[--><!--[--><!--[--><img class="vp-image dark logo" style="" src="/avatars/avatar.png" alt data-v-17210522><!--]--><!--[--><img class="vp-image light logo" style="" src="/avatars/avatar.png" alt data-v-17210522><!--]--><!--]--><!--]--><span data-v-78317e40>SaturnTsen</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-f0d7e165><div class="content-body" data-v-f0d7e165><!--[--><!--]--><div class="vp-navbar-search search" data-v-f0d7e165><div class="search-wrapper" data-v-895d8b33><!----><div id="local-search" data-v-895d8b33><button type="button" class="mini-search mini-search-button" aria-label="Search" data-v-895d8b33><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">Search</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><!--[--><!--]--><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-f0d7e165 data-v-dd33332d><span id="main-nav-aria-label" class="visually-hidden" data-v-dd33332d>Main Navigation</span><!--[--><!--[--><a class="vp-link link navbar-menu-link" href="/" tabindex="0" data-v-dd33332d data-v-caac0954><!--[--><!----><span data-v-caac0954>Home</span><!----><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-dd33332d data-v-3dde86b7><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-3dde86b7><span class="text" data-v-3dde86b7><!----><!----><span data-v-3dde86b7>Notes</span><!----><span class="vpi-chevron-down text-icon" data-v-3dde86b7></span></span></button><div class="menu" data-v-3dde86b7><div class="vp-menu" data-v-3dde86b7 data-v-55c02a15><div class="items" data-v-55c02a15><!--[--><!--[--><div class="vp-menu-link" data-v-55c02a15 data-v-b7034f0e><a class="vp-link link" href="/notes/um-cv/" data-v-b7034f0e><!--[--><!----> CV-NNDL <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-55c02a15 data-v-b7034f0e><a class="vp-link link" href="/notes/leetcode/" data-v-b7034f0e><!--[--><!----> LeetCode <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-55c02a15 data-v-b7034f0e><a class="vp-link link" href="/notes/misc/" data-v-b7034f0e><!--[--><!----> Misc <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!--[--><!--]--><!----><div class="vp-navbar-appearance appearance" data-v-f0d7e165 data-v-be794682><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-be794682 data-v-42684fe4 data-v-196dff46><span class="check" data-v-196dff46><span class="icon" data-v-196dff46><!--[--><span class="vpi-sun sun" data-v-42684fe4></span><span class="vpi-moon moon" data-v-42684fe4></span><!--]--></span></span></button></div><div class="vp-social-links vp-navbar-social-links social-links" data-v-f0d7e165 data-v-a8dae519 data-v-865113bf><!--[--><a class="vp-social-link no-icon" href="https://github.com/saturntsen" aria-label="github" target="_blank" rel="noopener" data-v-865113bf data-v-08f84eea><span class="vpi-social-github" /></a><!--]--></div><div class="vp-flyout vp-navbar-extra extra" data-v-f0d7e165 data-v-59aeafe8 data-v-3dde86b7><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-3dde86b7><span class="vpi-more-horizontal icon" data-v-3dde86b7></span></button><div class="menu" data-v-3dde86b7><div class="vp-menu" data-v-3dde86b7 data-v-55c02a15><!----><!--[--><!--[--><!----><div class="group" data-v-59aeafe8><div class="item appearance" data-v-59aeafe8><p class="label" data-v-59aeafe8>Appearance</p><div class="appearance-action" data-v-59aeafe8><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-59aeafe8 data-v-42684fe4 data-v-196dff46><span class="check" data-v-196dff46><span class="icon" data-v-196dff46><!--[--><span class="vpi-sun sun" data-v-42684fe4></span><span class="vpi-moon moon" data-v-42684fe4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-59aeafe8><div class="item social-links" data-v-59aeafe8><div class="vp-social-links social-links-list" data-v-59aeafe8 data-v-865113bf><!--[--><a class="vp-social-link no-icon" href="https://github.com/saturntsen" aria-label="github" target="_blank" rel="noopener" data-v-865113bf data-v-08f84eea><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-f0d7e165 data-v-c65a6891><span class="container" data-v-c65a6891><span class="top" data-v-c65a6891></span><span class="middle" data-v-c65a6891></span><span class="bottom" data-v-c65a6891></span></span></button></div></div></div></div><div class="divider" data-v-f0d7e165><div class="divider-line" data-v-f0d7e165></div></div></div><!----></header><div class="vp-local-nav reached-top" data-v-a218b6db data-v-e2935d30><button class="menu" aria-expanded="false" aria-controls="SidebarNav" data-v-e2935d30><span class="vpi-align-left menu-icon" data-v-e2935d30></span><span class="menu-text" data-v-e2935d30>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-e2935d30 data-v-ff10071c><button data-v-ff10071c>Return to top</button><!----></div></div><aside class="vp-sidebar" vp-sidebar data-v-a218b6db data-v-4f040617><div class="curtain" data-v-4f040617></div><nav id="SidebarNav" class="nav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-4f040617><span id="sidebar-aria-label" class="visually-hidden" data-v-4f040617> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-80522f8e><section class="vp-sidebar-item sidebar-item level-0 has-active" data-v-80522f8e data-v-467b1cf7><div class="item" role="button" tabindex="0" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><h2 class="text" data-v-467b1cf7><span data-v-467b1cf7>UM-CV</span><!----></h2><!----></div><div data-v-467b1cf7 data-v-467b1cf7><div class="items" data-v-467b1cf7><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>README</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-1/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>1 Intro</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-2/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>2 Image Classification</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-3-4/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>3 & 4 Linear Classifiers and Optimization</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-5/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>5 & 6 Neural Networks and Back Propagation</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/backprop-calc-1/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>Two-layer MLP backprop</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/backprop-calc-2/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>Batch Normalization backprop</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-7/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>7 & 8 CNN and its design principles</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-9/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>9 Hardware, Software, PyTorch Modules</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-10/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>10 & 11 Training Neural Networks</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-12/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>12 & 13 Recurrent Neural Networks & Attention Mechanism</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-14/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>14 Visualizing and understanding CNNs</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-15/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>15 Object Detection</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-16/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>16 Object Semantic Segmentation</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-17/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>17 3D Vision</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-18/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>18 Videos</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-19/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>19 Autoregressive Models, Variational Autoencoders</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-20/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>20 Generative Adversarial Networks</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-21/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>21 Reinforcement Learning</span><!----></p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><!--]--><!--[--><!--]--></nav></aside><!--[--><div id="VPContent" vp-content class="vp-content has-sidebar" data-v-a218b6db data-v-6e8aa8db><div class="vp-doc-container has-sidebar has-aside" data-v-6e8aa8db data-v-380c246c><!--[--><!--]--><div class="container" data-v-380c246c><div class="aside" vp-outline data-v-380c246c><div class="aside-curtain" data-v-380c246c></div><div class="aside-container" data-v-380c246c><div class="aside-content" data-v-380c246c><div class="vp-doc-aside" data-v-380c246c data-v-36d29b94><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="vp-doc-aside-outline" role="navigation" data-v-36d29b94 data-v-924d914c><div class="content" data-v-924d914c><div class="outline-marker" data-v-924d914c></div><div id="doc-outline-aria-label" aria-level="2" class="outline-title" role="heading" data-v-924d914c><span data-v-924d914c>On this page</span><span class="vpi-print icon" data-v-924d914c></span></div><ul class="root" data-v-924d914c data-v-fc78de7f><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-36d29b94></div><!--[--><!--]--></div></div></div></div><div class="content" data-v-380c246c><div class="content-container" data-v-380c246c><!--[--><!--]--><main class="main" data-v-380c246c><nav class="vp-breadcrumb" data-v-380c246c data-v-389ad6f0><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-389ad6f0><!--[--><li property="itemListElement" typeof="ListItem" data-v-389ad6f0><a class="vp-link link breadcrumb" href="/" property="item" typeof="WebPage" data-v-389ad6f0><!--[-->Home<!--]--><!----></a><span class="vpi-chevron-right" data-v-389ad6f0></span><meta property="name" content="Home" data-v-389ad6f0><meta property="position" content="1" data-v-389ad6f0></li><li property="itemListElement" typeof="ListItem" data-v-389ad6f0><span class="vp-link breadcrumb" property="item" typeof="WebPage" data-v-389ad6f0><!--[-->UM-CV<!--]--><!----></span><span class="vpi-chevron-right" data-v-389ad6f0></span><meta property="name" content="UM-CV" data-v-389ad6f0><meta property="position" content="2" data-v-389ad6f0></li><li property="itemListElement" typeof="ListItem" data-v-389ad6f0><a class="vp-link link breadcrumb current" href="/notes/um-cv/um-cv-14/" property="item" typeof="WebPage" data-v-389ad6f0><!--[-->14 Visualizing and understanding CNNs<!--]--><!----></a><!----><meta property="name" content="14 Visualizing and understanding CNNs" data-v-389ad6f0><meta property="position" content="3" data-v-389ad6f0></li><!--]--></ol></nav><!--[--><!--]--><!--[--><h1 class="vp-doc-title page-title" data-v-8dd3566a><!----> 14 Visualizing and understanding CNNs <!----></h1><div class="vp-doc-meta" data-v-8dd3566a><!--[--><!--]--><p class="reading-time" data-v-8dd3566a><span class="vpi-books icon" data-v-8dd3566a></span><span data-v-8dd3566a>About 1807 words</span><span data-v-8dd3566a>About 6 min</span></p><p data-v-8dd3566a><span class="vpi-tag icon" data-v-8dd3566a></span><!--[--><span class="vp-link tag vp-tag-9wic" data-v-8dd3566a><!--[-->notes<!--]--><!----></span><span class="vp-link tag vp-tag-akhq" data-v-8dd3566a><!--[-->computer-vision<!--]--><!----></span><!--]--></p><!--[--><!--]--><p class="create-time" data-v-8dd3566a><span class="vpi-clock icon" data-v-8dd3566a></span><span data-v-8dd3566a>2024-12-27</span></p></div><!--]--><!--[--><!--]--><div class="_notes_um-cv_um-cv-14_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-380c246c><!--[--><!--]--><div data-v-380c246c><p>Various techniques to visualize and understand CNNs. <strong>Activations:</strong> Nearest neighbors, PCA, t-SNE, saliency, occlusion, backpropagation. <strong>Gradients:</strong> Saliency maps, class visualization, fooling images, feature inversion. <strong>Fun:</strong> DeepDream, texture synthesis, style transfer.</p><p>@Credits: <a href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/" target="_blank" rel="noopener noreferrer">EECS 498.007</a> | Video Lecture: <a href="https://www.youtube.com/watch?v=dJYGatp4SvA&amp;list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r" target="_blank" rel="noopener noreferrer">UM-CV</a></p><p>Personal work for the assignments of the course: <a href="https://github.com/SaturnTsen/EECS-498-007/" target="_blank" rel="noopener noreferrer">github repo</a>.</p><p><strong>Notice on Usage and Attribution</strong></p><p>These are personal class notes based on the University of Michigan EECS 498.008 / 598.008 course. They are intended solely for personal learning and academic discussion, with no commercial use.</p><p>For detailed information, please refer to the <strong><a href="#notice-on-usage-and-attribution">complete notice at the end of this document</a></strong></p><h2 id="visualizing-layers" tabindex="-1"><a class="header-anchor" href="#visualizing-layers"><span>Visualizing layers</span></a></h2><h3 id="first-layer-visualize-filters" tabindex="-1"><a class="header-anchor" href="#first-layer-visualize-filters"><span>First layer: Visualize filters</span></a></h3><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-1.png" width="70%" alt="First layer: Visualize filters"><br> Fig: Convolutional filters on the first layer</div><p><a href="https://arxiv.org/abs/1404.5997" target="_blank" rel="noopener noreferrer">One weird trick for parallelizing convolutional neural networks</a></p><p>&quot;Template matching&quot;. Idea: inner product between filter and image region. Visualizing filters can give us some insight into what the network is looking for. Recall that Mammalian visual cortex has simple cells and complex cells. Simple cells are edge detectors, complex cells are invariant to position.</p><h3 id="higher-layers" tabindex="-1"><a class="header-anchor" href="#higher-layers"><span>Higher Layers</span></a></h3><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-2.png" width="70%" alt="Higher Layers: Visualize Filters"><br>Figs: Filters on higher layers</div><p>Intermediate convolutional layers are more difficult to interpret.</p><h3 id="last-layer" tabindex="-1"><a class="header-anchor" href="#last-layer"><span>Last Layer</span></a></h3><p>Run the network on an image and visualize the activations of the last layer.</p><h4 id="nearest-neighbors" tabindex="-1"><a class="header-anchor" href="#nearest-neighbors"><span>Nearest Neighbors</span></a></h4><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-3.png" width="70%" alt="Nearest Neighbors"><br>Fig: Nearest Neighbors</div><p>All of the nearest neighbors are of the same class. This is a good sign that the low-level pixel content are ignored and the network is focusing on the high-level content.</p><h4 id="dimensionality-reduction-pca-t-sne" tabindex="-1"><a class="header-anchor" href="#dimensionality-reduction-pca-t-sne"><span>Dimensionality Reduction: PCA/t-SNE</span></a></h4><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-4.png" width="70%" alt="Dimensionality Reduction: PCA"><br>Fig: Dimensionality Reduction: PCA</div><p>t-SNE is a more complex method that tries to preserve the local structure of the data.</p><p>The ten clusters are correspond to the ten classes of MNIST.</p><p>See also <a href="http://cs.stanford.edu/people/karpathy/cnnembed/" target="_blank" rel="noopener noreferrer">high-resolution version</a>. (Recommended, really interesting)</p><h2 id="visualizing-activations" tabindex="-1"><a class="header-anchor" href="#visualizing-activations"><span>Visualizing Activations</span></a></h2><p>Idea: Given an image, visualize the activations of the network at each layer. This gives a sense of what the neurons might be responding to.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-5.png" width="70%" alt="Visualizing Activations"><br>Fig: Visualizing Activations</div><p>Why are there so many zeros ? Because of the ReLU activation function. The way to squash the image might also have an effect on the visualization.</p><h2 id="maximally-activating-patches" tabindex="-1"><a class="header-anchor" href="#maximally-activating-patches"><span>Maximally Activating Patches</span></a></h2><p>Run the model on all images, and for a given neuron, find the images that maximally activate that neuron.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-6.png" width="70%" alt="Maximally Activating Patches"><br>Fig: Maximally Activating Patches</div><h2 id="saliency-via-occlusion" tabindex="-1"><a class="header-anchor" href="#saliency-via-occlusion"><span>Saliency via Occlusion</span></a></h2><p>Pass the masked image through the network and see how the output changes.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-7.png" width="70%" alt="Saliency via Occlusion"><br>Fig: Saliency via Occlusion</div><p>Computationally expensive.</p><h2 id="saliency-via-backpropagation" tabindex="-1"><a class="header-anchor" href="#saliency-via-backpropagation"><span>Saliency via backpropagation</span></a></h2><p>Compute the gradient of the output with respect to the <strong>input</strong>.</p><p>This represents if we change the pixels a little bit, how much would it affect the score at the end.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-8.png" width="70%" alt="Saliency via backpropagation"><br>Fig: Saliency via backpropagation</div><p>(Most real examples do not look this good)</p><h2 id="saliency-maps-segmentation-without-supervision" tabindex="-1"><a class="header-anchor" href="#saliency-maps-segmentation-without-supervision"><span>Saliency Maps: Segmentation without supervision</span></a></h2><p>We can use classification models to generate segmentation masks.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-9.png" width="70%" alt="Saliency Maps: Segmentation without supervision"><br>Fig: Saliency Maps: Segmentation without supervision</div><h2 id="gradient-information-for-intermediate-layers" tabindex="-1"><a class="header-anchor" href="#gradient-information-for-intermediate-layers"><span>Gradient information for intermediate layers</span></a></h2><p>Intermediate Features via (guided) backpropagation. The idea is similar to saliency via backpropagation, but if we do it directly, the results will be noisy. Instead, we use &quot;guided backpropagation&quot; to get cleaner results.</p><p>In forward pass, negative values are clamp to zero, and the gradients of the negative values are set to zero. In the backward pass, we also add a ReLU to the gradients, so that only positive gradients are propagated back. (Heuristic that works in practice)</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-10.png" width="70%" alt="Guided Backpropagation"></div><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-11.png" width="70%" alt="Guided Backpropagation"><br>Fig: Guided Backpropagation</div><h2 id="gradient-ascent" tabindex="-1"><a class="header-anchor" href="#gradient-ascent"><span>Gradient Ascent</span></a></h2><p>Generate an image that maximizes the activation of a neuron (using gradient ascent).</p><p>Initialize original image to zero, and then update the image to maximize the activation of a neuron.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-12.png" width="70%" alt="Gradient Ascent"><br>Fig: Gradient Ascent</div><p>Using other regularizers:</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-13.png" width="70%" alt="Gradient Ascent"><br>Fig: Gradient Ascent</div><p>Use the same approach to visualize intermediate features:</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-14.png" width="70%" alt="Gradient Ascent"><br>Fig: Gradient Ascent</div><h2 id="adversarial-examples" tabindex="-1"><a class="header-anchor" href="#adversarial-examples"><span>Adversarial Examples</span></a></h2><p>If we do not add regularizers, we can generate adversarial examples that looks like noise but can fool the network.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-15.png" width="70%" alt="Adversarial Examples"><br>Fig: Adversarial Examples</div><h2 id="feature-inversion" tabindex="-1"><a class="header-anchor" href="#feature-inversion"><span>Feature Inversion</span></a></h2><ul><li><strong>Feature Inversion</strong>: Given a <strong>feature vector</strong>, by minimizing the difference between the new input feature and the original feature, <strong>reconstruct</strong> an input data (such as an image).</li><li><strong>Gradient Ascent</strong>: By adjusting the input data, <strong>maximize the activation value of a specific neuron</strong>, and generate an input that maximizes the activation value of the neuron.</li></ul><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-16.png" width="70%" alt="Feature Inversion"><br>Fig: Feature Inversion</div><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-17.png" width="70%" alt="Feature Inversion"><br>Fig: Feature Inversion</div><p>As we go up through the network, the overall structure is preserved but the details are lost. e.g. textures</p><h2 id="deepdream-amplifying-existing-features" tabindex="-1"><a class="header-anchor" href="#deepdream-amplifying-existing-features"><span>DeepDream: Amplifying existing features</span></a></h2><p>Take an existing image and amplify the features that are already present in the image.</p><p>Idea: Start with an image, run it through the network, and then update the image to maximize the activation of a neuron.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-18.png" width="70%" alt="DeepDream"><br>Fig: DeepDream</div><p>This needs to get good regularizers to get good results.</p><p>DeepDream to lower layer networks:</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-19.png" width="70%" alt="DeepDream"><br>Fig: DeepDream</div><p>Higher layers:</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-20.png" width="70%" alt="DeepDream"><br>Fig: DeepDream</div><p>Patterns are shown out over and over again.</p><p>DeepDream for a long time:</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-21.png" width="70%" alt="DeepDream"><br>Fig: DeepDream</div><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-22.png" width="70%" alt="DeepDream"><br>Fig: DeepDream</div><h2 id="application-texture-synthesis" tabindex="-1"><a class="header-anchor" href="#application-texture-synthesis"><span>Application: Texture Synthesis</span></a></h2><p>Nearest Neighbor: SIGGRAPH 2000</p><p>Gram Matrix: Correlation. This tells us which features tends to co-occur in the input image. We can perform texture synthesis by matching the Gram matrix using gradient ascent.</p><p>Since Gram Matrices are invariant to translation, we can expect to generate textures that are invariant to translation.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-23.png" width="70%" alt="Texture Synthesis"><br>Fig: Texture Synthesis</div><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-24.png" width="70%" alt="Texture Synthesis"><br>Fig: Texture Synthesis</div><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-25.png" width="70%" alt="Texture Synthesis"><br>Fig: Texture Synthesis</div><h2 id="application-style-transfer" tabindex="-1"><a class="header-anchor" href="#application-style-transfer"><span>Application: Style Transfer</span></a></h2><p>Feature + Gram Joint Reconstruction</p><p>Content Image + Style Image</p><p>CVPR 2016</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-26.png" width="70%" alt="Style Transfer"><br>Fig: Style Transfer</div><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-27.png" width="70%" alt="Style Transfer"><br>Fig: Style Transfer</div><p>We can toggle the weight between the content and style images to get different results.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-28.png" width="70%" alt="Style Transfer"><br>Fig: Style Transfer</div><p>Multiple Image Style Transfer:</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-29.png" width="70%" alt="Style Transfer"><br>Fig: Style Transfer</div><p>Problem: Super slow. Style transfer requires many forward/backward passes through VGG; very slow!</p><p>Solution: Train another neural network to perform style transfer.</p><div style="text-align:center;margin-bottom:1em;"><img src="/images/um-cv/14-30.png" width="70%" alt="Style Transfer"><br>Fig: Style Transfer</div><h2 id="notice-on-usage-and-attribution" tabindex="-1"><a class="header-anchor" href="#notice-on-usage-and-attribution"><span><strong>Notice on Usage and Attribution</strong></span></a></h2><p>This note is based on the <strong>University of Michigan&#39;s publicly available course EECS 498.008 / 598.008</strong> and is intended <strong>solely for personal learning and academic discussion</strong>, with no commercial use.</p><ul><li><strong>Nature of the Notes:</strong> These notes include extensive references and citations from course materials to ensure clarity and completeness. However, they are presented as personal interpretations and summaries, not as substitutes for the original course content.</li><li><strong>Original Course Resources:</strong> Please refer to the official <a href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/" target="_blank" rel="noopener noreferrer"><strong>University of Michigan website</strong></a> for complete and accurate course materials.</li><li><strong>Third-Party Open Access Content:</strong> This note may reference Open Access (OA) papers or resources cited within the course materials. These materials are used under their original Open Access licenses (e.g., CC BY, CC BY-SA).</li><li><strong>Proper Attribution:</strong> Every referenced OA resource is appropriately cited, including the author, publication title, source link, and license type.</li><li><strong>Copyright Notice:</strong> All rights to third-party content remain with their respective authors or publishers.</li><li><strong>Content Removal:</strong> If you believe any content infringes on your copyright, please contact me, and I will promptly remove the content in question.</li></ul><p>Thanks to the <strong>University of Michigan</strong> and the contributors to the course for their openness and dedication to accessible education.</p></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-380c246c data-v-7bfa3324><!--[--><!--]--><div class="edit-info" data-v-7bfa3324><div class="edit-link" data-v-7bfa3324><a class="vp-link link no-icon edit-link-button" href="https://github.com/SaturnTsen/saturntsen.github.io/edit/main/docs/notes/UM-CV/UM-CV 14 Visualizing and understanding CNNs.md" target="_blank" rel="noreferrer" data-v-7bfa3324><!--[--><span class="vpi-square-pen edit-link-icon" aria-label="edit icon" data-v-7bfa3324></span> Edit this page<!--]--><!----></a></div><!----></div><div class="contributors" aria-label="Contributors" data-v-7bfa3324><span class="contributors-label" data-v-7bfa3324>Contributors: </span><span class="contributors-info" data-v-7bfa3324><!--[--><!--[--><span class="contributor" data-v-7bfa3324>SaturnTsen</span><!----><!--]--><!--]--></span></div><nav class="prev-next" data-v-7bfa3324><div class="pager" data-v-7bfa3324><a class="vp-link link pager-link prev" href="/notes/um-cv/um-cv-12/" data-v-7bfa3324><!--[--><span class="desc" data-v-7bfa3324>Previous page</span><span class="title" data-v-7bfa3324>12 & 13 Recurrent Neural Networks & Attention Mechanism</span><!--]--><!----></a></div><div class="pager" data-v-7bfa3324><a class="vp-link link pager-link next" href="/notes/um-cv/um-cv-15/" data-v-7bfa3324><!--[--><span class="desc" data-v-7bfa3324>Next page</span><span class="title" data-v-7bfa3324>15 Object Detection</span><!--]--><!----></a></div></nav></footer><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;" data-v-380c246c><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div></div><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-a218b6db data-v-6955073a><span class="percent" data-allow-mismatch data-v-6955073a>0%</span><span class="show icon vpi-back-to-top" data-v-6955073a></span><svg aria-hidden="true" data-v-6955073a><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-6955073a></circle></svg></button><footer class="vp-footer has-sidebar" vp-footer data-v-a218b6db data-v-d9d63044><!--[--><div class="container" data-v-d9d63044><p class="message" data-v-d9d63044>Powered by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://theme-plume.vuejs.press">vuepress-theme-plume</a></p><p class="copyright" data-v-d9d63044>© 2024 SaturnTsen | Powered by <a href="https://vuepress.vuejs.org/" target="_blank">VuePress</a> & <a href="https://theme-plume.vuejs.press/" target="_blank">Plume</a></p></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-BPmJL-vo.js" defer></script></body></html>