<!doctype html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.24" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.161" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"18 Videos","image":[""],"dateModified":"2025-02-21T17:44:17.000Z","author":[]}</script><meta property="og:url" content="https://saturntsen.github.io/notes/um-cv/um-cv-18/"><meta property="og:site_name" content="SaturnTsen"><meta property="og:title" content="18 Videos"><meta property="og:description" content="Summary: Video Classification, CNN Architectures for Videos, Two-Stream Networks, Recurrent Structures, Spatial-Temporal Detection, and more. @Credits: EECS 498.007 | Video Lect..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-02-21T17:44:17.000Z"><meta property="article:tag" content="computer-vision"><meta property="article:modified_time" content="2025-02-21T17:44:17.000Z"><link rel="icon" href="/favicon.ico"><title>18 Videos | SaturnTsen</title><meta name="description" content="Summary: Video Classification, CNN Architectures for Videos, Two-Stream Networks, Recurrent Structures, Spatial-Temporal Detection, and more. @Credits: EECS 498.007 | Video Lect..."><link rel="preload" href="/assets/style-CU0EtsvZ.css" as="style"><link rel="stylesheet" href="/assets/style-CU0EtsvZ.css"><link rel="modulepreload" href="/assets/app-BPmJL-vo.js"><link rel="modulepreload" href="/assets/index.html-DnU5krJy.js"><link rel="prefetch" href="/assets/index.html-BmG4TjtM.js" as="script"><link rel="prefetch" href="/assets/index.html-BQ1NaJuK.js" as="script"><link rel="prefetch" href="/assets/index.html-vVZNyw0-.js" as="script"><link rel="prefetch" href="/assets/index.html-ZDreb-Cr.js" as="script"><link rel="prefetch" href="/assets/index.html-DnwmR40J.js" as="script"><link rel="prefetch" href="/assets/index.html-DqKRuwzh.js" as="script"><link rel="prefetch" href="/assets/index.html-BnO6pfWi.js" as="script"><link rel="prefetch" href="/assets/index.html-DqrV2oWi.js" as="script"><link rel="prefetch" href="/assets/index.html-D0505yVi.js" as="script"><link rel="prefetch" href="/assets/index.html-D4PfOoAo.js" as="script"><link rel="prefetch" href="/assets/index.html-OZtXDBX-.js" as="script"><link rel="prefetch" href="/assets/index.html-DB8OfTW0.js" as="script"><link rel="prefetch" href="/assets/index.html-Bf7LPeAD.js" as="script"><link rel="prefetch" href="/assets/index.html-Cf43ABLN.js" as="script"><link rel="prefetch" href="/assets/index.html-Dwovho6D.js" as="script"><link rel="prefetch" href="/assets/index.html-83zXgr4a.js" as="script"><link rel="prefetch" href="/assets/index.html-BLtwLLZI.js" as="script"><link rel="prefetch" href="/assets/index.html-BUZheLiL.js" as="script"><link rel="prefetch" href="/assets/index.html-YZrr0wBf.js" as="script"><link rel="prefetch" href="/assets/index.html-bkdbp8wU.js" as="script"><link rel="prefetch" href="/assets/index.html-CWFawhma.js" as="script"><link rel="prefetch" href="/assets/index.html-DGAYbThF.js" as="script"><link rel="prefetch" href="/assets/index.html-C46ohglK.js" as="script"><link rel="prefetch" href="/assets/index.html-CSRYllLl.js" as="script"><link rel="prefetch" href="/assets/index.html-Cnmy6xJA.js" as="script"><link rel="prefetch" href="/assets/index.html-KI14JA6V.js" as="script"><link rel="prefetch" href="/assets/index.html-CFqE0fIB.js" as="script"><link rel="prefetch" href="/assets/index.html-Cp3T_Wdm.js" as="script"><link rel="prefetch" href="/assets/index.html-C5T_LiKK.js" as="script"><link rel="prefetch" href="/assets/index.html-RGl9jofY.js" as="script"><link rel="prefetch" href="/assets/index.html-C2o8eR02.js" as="script"><link rel="prefetch" href="/assets/index.html-C4s21r8r.js" as="script"><link rel="prefetch" href="/assets/index.html-BGMJZV3q.js" as="script"><link rel="prefetch" href="/assets/index.html-BnGAEkBd.js" as="script"><link rel="prefetch" href="/assets/index.html-f3JN0p-H.js" as="script"><link rel="prefetch" href="/assets/index.html-D3JrJcoe.js" as="script"><link rel="prefetch" href="/assets/index.html-DZjtQU4g.js" as="script"><link rel="prefetch" href="/assets/index.html-DPDml381.js" as="script"><link rel="prefetch" href="/assets/index.html-D-DIxWNy.js" as="script"><link rel="prefetch" href="/assets/index.html-M3FNVy5f.js" as="script"><link rel="prefetch" href="/assets/index.html-BxBVeWuK.js" as="script"><link rel="prefetch" href="/assets/index.html-pBhdW37w.js" as="script"><link rel="prefetch" href="/assets/index.html-CMGEEupf.js" as="script"><link rel="prefetch" href="/assets/index.html-XKTeTmUn.js" as="script"><link rel="prefetch" href="/assets/index.html-Nwfmu88j.js" as="script"><link rel="prefetch" href="/assets/index.html-DzKok2JV.js" as="script"><link rel="prefetch" href="/assets/index.html-CzQ1v4M_.js" as="script"><link rel="prefetch" href="/assets/index.html-b5bM2Mm0.js" as="script"><link rel="prefetch" href="/assets/index.html-4FD4vMR_.js" as="script"><link rel="prefetch" href="/assets/index.html-CELX4Gv6.js" as="script"><link rel="prefetch" href="/assets/index.html-DAuv_XsY.js" as="script"><link rel="prefetch" href="/assets/index.html-D0HnbJld.js" as="script"><link rel="prefetch" href="/assets/index.html-cizS7tpp.js" as="script"><link rel="prefetch" href="/assets/index.html-Db9qbygp.js" as="script"><link rel="prefetch" href="/assets/index.html-BC33mLRG.js" as="script"><link rel="prefetch" href="/assets/index.html-Bgjlk9gZ.js" as="script"><link rel="prefetch" href="/assets/index.html-DNyhKRbF.js" as="script"><link rel="prefetch" href="/assets/index.html-MHkPnQ_o.js" as="script"><link rel="prefetch" href="/assets/index.html-gtR08_vy.js" as="script"><link rel="prefetch" href="/assets/index.html-CoqucIIR.js" as="script"><link rel="prefetch" href="/assets/index.html-B6BIthZU.js" as="script"><link rel="prefetch" href="/assets/index.html-BKoKQbyt.js" as="script"><link rel="prefetch" href="/assets/index.html-Bshhoiba.js" as="script"><link rel="prefetch" href="/assets/index.html-nu7-Thlm.js" as="script"><link rel="prefetch" href="/assets/index.html-B1_Iy3K7.js" as="script"><link rel="prefetch" href="/assets/index.html-C5N22UG4.js" as="script"><link rel="prefetch" href="/assets/index.html-C2esroDP.js" as="script"><link rel="prefetch" href="/assets/index.html-BwFyN5XX.js" as="script"><link rel="prefetch" href="/assets/index.html-Cr91GHno.js" as="script"><link rel="prefetch" href="/assets/index.html-D6YLzvpj.js" as="script"><link rel="prefetch" href="/assets/index.html-Ds6znEeN.js" as="script"><link rel="prefetch" href="/assets/index.html-CAJn5R2r.js" as="script"><link rel="prefetch" href="/assets/index.html-CfYOQ07j.js" as="script"><link rel="prefetch" href="/assets/index.html-BpdD7CET.js" as="script"><link rel="prefetch" href="/assets/404.html-BRfb-qcV.js" as="script"><link rel="prefetch" href="/assets/index.html-DN0XcQYf.js" as="script"><link rel="prefetch" href="/assets/index.html-BrfGEaVq.js" as="script"><link rel="prefetch" href="/assets/index.html-DPdADZ69.js" as="script"><link rel="prefetch" href="/assets/index.html-Cxk-aAuN.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CKV1Bsxh.js" as="script"><link rel="prefetch" href="/assets/giscus-BACEvYzX.js" as="script"><link rel="prefetch" href="/assets/searchBox-default-BgWbHU8C.js" as="script"><link rel="prefetch" href="/assets/SearchBox-D0_iY6j8.js" as="script"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-a218b6db><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-7a21891b></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-7a21891b> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-a218b6db data-v-cfd3cabe><div class="vp-navbar" vp-navbar data-v-cfd3cabe data-v-f0d7e165><div class="wrapper" data-v-f0d7e165><div class="container" data-v-f0d7e165><div class="title" data-v-f0d7e165><div class="vp-navbar-title has-sidebar" data-v-f0d7e165 data-v-78317e40><a class="vp-link link no-icon title" href="/" data-v-78317e40><!--[--><!--[--><!--]--><!--[--><!--[--><!--[--><img class="vp-image dark logo" style="" src="/avatars/avatar.png" alt data-v-17210522><!--]--><!--[--><img class="vp-image light logo" style="" src="/avatars/avatar.png" alt data-v-17210522><!--]--><!--]--><!--]--><span data-v-78317e40>SaturnTsen</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-f0d7e165><div class="content-body" data-v-f0d7e165><!--[--><!--]--><div class="vp-navbar-search search" data-v-f0d7e165><div class="search-wrapper" data-v-895d8b33><!----><div id="local-search" data-v-895d8b33><button type="button" class="mini-search mini-search-button" aria-label="Search" data-v-895d8b33><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">Search</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><!--[--><!--]--><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-f0d7e165 data-v-dd33332d><span id="main-nav-aria-label" class="visually-hidden" data-v-dd33332d>Main Navigation</span><!--[--><!--[--><a class="vp-link link navbar-menu-link" href="/" tabindex="0" data-v-dd33332d data-v-caac0954><!--[--><!----><span data-v-caac0954>Home</span><!----><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-dd33332d data-v-3dde86b7><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-3dde86b7><span class="text" data-v-3dde86b7><!----><!----><span data-v-3dde86b7>Notes</span><!----><span class="vpi-chevron-down text-icon" data-v-3dde86b7></span></span></button><div class="menu" data-v-3dde86b7><div class="vp-menu" data-v-3dde86b7 data-v-55c02a15><div class="items" data-v-55c02a15><!--[--><!--[--><div class="vp-menu-link" data-v-55c02a15 data-v-b7034f0e><a class="vp-link link" href="/notes/um-cv/" data-v-b7034f0e><!--[--><!----> CV-NNDL <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-55c02a15 data-v-b7034f0e><a class="vp-link link" href="/notes/leetcode/" data-v-b7034f0e><!--[--><!----> LeetCode <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-55c02a15 data-v-b7034f0e><a class="vp-link link" href="/notes/misc/" data-v-b7034f0e><!--[--><!----> Misc <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!--[--><!--]--><!----><div class="vp-navbar-appearance appearance" data-v-f0d7e165 data-v-be794682><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-be794682 data-v-42684fe4 data-v-196dff46><span class="check" data-v-196dff46><span class="icon" data-v-196dff46><!--[--><span class="vpi-sun sun" data-v-42684fe4></span><span class="vpi-moon moon" data-v-42684fe4></span><!--]--></span></span></button></div><div class="vp-social-links vp-navbar-social-links social-links" data-v-f0d7e165 data-v-a8dae519 data-v-865113bf><!--[--><a class="vp-social-link no-icon" href="https://github.com/saturntsen" aria-label="github" target="_blank" rel="noopener" data-v-865113bf data-v-08f84eea><span class="vpi-social-github" /></a><!--]--></div><div class="vp-flyout vp-navbar-extra extra" data-v-f0d7e165 data-v-59aeafe8 data-v-3dde86b7><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-3dde86b7><span class="vpi-more-horizontal icon" data-v-3dde86b7></span></button><div class="menu" data-v-3dde86b7><div class="vp-menu" data-v-3dde86b7 data-v-55c02a15><!----><!--[--><!--[--><!----><div class="group" data-v-59aeafe8><div class="item appearance" data-v-59aeafe8><p class="label" data-v-59aeafe8>Appearance</p><div class="appearance-action" data-v-59aeafe8><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-59aeafe8 data-v-42684fe4 data-v-196dff46><span class="check" data-v-196dff46><span class="icon" data-v-196dff46><!--[--><span class="vpi-sun sun" data-v-42684fe4></span><span class="vpi-moon moon" data-v-42684fe4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-59aeafe8><div class="item social-links" data-v-59aeafe8><div class="vp-social-links social-links-list" data-v-59aeafe8 data-v-865113bf><!--[--><a class="vp-social-link no-icon" href="https://github.com/saturntsen" aria-label="github" target="_blank" rel="noopener" data-v-865113bf data-v-08f84eea><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-f0d7e165 data-v-c65a6891><span class="container" data-v-c65a6891><span class="top" data-v-c65a6891></span><span class="middle" data-v-c65a6891></span><span class="bottom" data-v-c65a6891></span></span></button></div></div></div></div><div class="divider" data-v-f0d7e165><div class="divider-line" data-v-f0d7e165></div></div></div><!----></header><div class="vp-local-nav reached-top" data-v-a218b6db data-v-e2935d30><button class="menu" aria-expanded="false" aria-controls="SidebarNav" data-v-e2935d30><span class="vpi-align-left menu-icon" data-v-e2935d30></span><span class="menu-text" data-v-e2935d30>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-e2935d30 data-v-ff10071c><button data-v-ff10071c>Return to top</button><!----></div></div><aside class="vp-sidebar" vp-sidebar data-v-a218b6db data-v-4f040617><div class="curtain" data-v-4f040617></div><nav id="SidebarNav" class="nav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-4f040617><span id="sidebar-aria-label" class="visually-hidden" data-v-4f040617> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-80522f8e><section class="vp-sidebar-item sidebar-item level-0 has-active" data-v-80522f8e data-v-467b1cf7><div class="item" role="button" tabindex="0" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><h2 class="text" data-v-467b1cf7><span data-v-467b1cf7>UM-CV</span><!----></h2><!----></div><div data-v-467b1cf7 data-v-467b1cf7><div class="items" data-v-467b1cf7><!--[--><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>README</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-1/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>1 Intro</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-2/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>2 Image Classification</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-3-4/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>3 & 4 Linear Classifiers and Optimization</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-5/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>5 & 6 Neural Networks and Back Propagation</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/backprop-calc-1/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>Two-layer MLP backprop</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/backprop-calc-2/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>Batch Normalization backprop</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-7/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>7 & 8 CNN and its design principles</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-9/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>9 Hardware, Software, PyTorch Modules</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-10/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>10 & 11 Training Neural Networks</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-12/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>12 & 13 Recurrent Neural Networks & Attention Mechanism</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-14/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>14 Visualizing and understanding CNNs</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-15/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>15 Object Detection</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-16/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>16 Object Semantic Segmentation</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-17/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>17 3D Vision</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-18/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>18 Videos</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-19/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>19 Autoregressive Models, Variational Autoencoders</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-20/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>20 Generative Adversarial Networks</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-1 is-link" data-v-467b1cf7 data-v-467b1cf7><div class="item" data-v-467b1cf7><div class="indicator" data-v-467b1cf7></div><!----><a class="vp-link link link" href="/notes/um-cv/um-cv-21/" data-v-467b1cf7><!--[--><p class="text" data-v-467b1cf7><span data-v-467b1cf7>21 Reinforcement Learning</span><!----></p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section></div><!--]--><!--[--><!--]--></nav></aside><!--[--><div id="VPContent" vp-content class="vp-content has-sidebar" data-v-a218b6db data-v-6e8aa8db><div class="vp-doc-container has-sidebar has-aside" data-v-6e8aa8db data-v-380c246c><!--[--><!--]--><div class="container" data-v-380c246c><div class="aside" vp-outline data-v-380c246c><div class="aside-curtain" data-v-380c246c></div><div class="aside-container" data-v-380c246c><div class="aside-content" data-v-380c246c><div class="vp-doc-aside" data-v-380c246c data-v-36d29b94><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="vp-doc-aside-outline" role="navigation" data-v-36d29b94 data-v-924d914c><div class="content" data-v-924d914c><div class="outline-marker" data-v-924d914c></div><div id="doc-outline-aria-label" aria-level="2" class="outline-title" role="heading" data-v-924d914c><span data-v-924d914c>On this page</span><span class="vpi-print icon" data-v-924d914c></span></div><ul class="root" data-v-924d914c data-v-fc78de7f><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-36d29b94></div><!--[--><!--]--></div></div></div></div><div class="content" data-v-380c246c><div class="content-container" data-v-380c246c><!--[--><!--]--><main class="main" data-v-380c246c><nav class="vp-breadcrumb" data-v-380c246c data-v-389ad6f0><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-389ad6f0><!--[--><li property="itemListElement" typeof="ListItem" data-v-389ad6f0><a class="vp-link link breadcrumb" href="/" property="item" typeof="WebPage" data-v-389ad6f0><!--[-->Home<!--]--><!----></a><span class="vpi-chevron-right" data-v-389ad6f0></span><meta property="name" content="Home" data-v-389ad6f0><meta property="position" content="1" data-v-389ad6f0></li><li property="itemListElement" typeof="ListItem" data-v-389ad6f0><span class="vp-link breadcrumb" property="item" typeof="WebPage" data-v-389ad6f0><!--[-->UM-CV<!--]--><!----></span><span class="vpi-chevron-right" data-v-389ad6f0></span><meta property="name" content="UM-CV" data-v-389ad6f0><meta property="position" content="2" data-v-389ad6f0></li><li property="itemListElement" typeof="ListItem" data-v-389ad6f0><a class="vp-link link breadcrumb current" href="/notes/um-cv/um-cv-18/" property="item" typeof="WebPage" data-v-389ad6f0><!--[-->18 Videos<!--]--><!----></a><!----><meta property="name" content="18 Videos" data-v-389ad6f0><meta property="position" content="3" data-v-389ad6f0></li><!--]--></ol></nav><!--[--><!--]--><!--[--><h1 class="vp-doc-title page-title" data-v-8dd3566a><!----> 18 Videos <!----></h1><div class="vp-doc-meta" data-v-8dd3566a><!--[--><!--]--><p class="reading-time" data-v-8dd3566a><span class="vpi-books icon" data-v-8dd3566a></span><span data-v-8dd3566a>About 1306 words</span><span data-v-8dd3566a>About 4 min</span></p><p data-v-8dd3566a><span class="vpi-tag icon" data-v-8dd3566a></span><!--[--><span class="vp-link tag vp-tag-akhq" data-v-8dd3566a><!--[-->computer-vision<!--]--><!----></span><!--]--></p><!--[--><!--]--><p class="create-time" data-v-8dd3566a><span class="vpi-clock icon" data-v-8dd3566a></span><span data-v-8dd3566a>2025-01-05</span></p></div><!--]--><!--[--><!--]--><div class="_notes_um-cv_um-cv-18_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-380c246c><!--[--><!--]--><div data-v-380c246c><p>Summary: Video Classification, CNN Architectures for Videos, Two-Stream Networks, Recurrent Structures, Spatial-Temporal Detection, and more.</p><p>@Credits: <a href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/" target="_blank" rel="noopener noreferrer">EECS 498.007</a> | Video Lecture: <a href="https://www.youtube.com/watch?v=dJYGatp4SvA&amp;list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r" target="_blank" rel="noopener noreferrer">UM-CV</a></p><p>Personal work for the assignments of the course: <a href="https://github.com/SaturnTsen/EECS-498-007/" target="_blank" rel="noopener noreferrer">github repo</a>.</p><p><strong>Notice on Usage and Attribution</strong></p><p>These are personal class notes based on the University of Michigan EECS 498.008 / 598.008 course. They are intended solely for personal learning and academic discussion, with no commercial use.</p><p>For detailed information, please refer to the <strong><a href="#notice-on-usage-and-attribution">complete notice at the end of this document</a></strong></p><h2 id="intro" tabindex="-1"><a class="header-anchor" href="#intro"><span>Intro</span></a></h2><p>A video is a sequence of images over time. We can think of a video as a 4D tensor: (T, C, H, W).</p><ul><li>T: time, C: channels, H: height, W: width</li></ul><h3 id="today-video-classification" tabindex="-1"><a class="header-anchor" href="#today-video-classification"><span>Today: Video Classification</span></a></h3><p>Images: Recognize objects</p><ul><li>Dog, Cat, Fish, Truck</li></ul><p>Videos: Recognize actions</p><ul><li>Swimming, Running, Jumping, Eating, Standing</li></ul><h3 id="training-on-clips" tabindex="-1"><a class="header-anchor" href="#training-on-clips"><span>Training on Clips</span></a></h3><p>Uncompressed video: 3 bytes per pixel</p><ul><li>SD (640x480)：~1.5 GB per minute</li><li>HD (1920x1080): ~5 GB per minute</li></ul><p>Solution: Train on short clips</p><ul><li>Low fps and low spatial resolution. e.g. T=16, H=W=112 (3.2 seconds at 5 fps, 588KB) -Testing: Run model on different clips, average predictions.</li></ul><h2 id="cnn-architectures-for-videos" tabindex="-1"><a class="header-anchor" href="#cnn-architectures-for-videos"><span>CNN Architectures for Videos</span></a></h2><h3 id="single-frame-cnn" tabindex="-1"><a class="header-anchor" href="#single-frame-cnn"><span>Single-Frame CNN</span></a></h3><p>Simple idea: train a normal 2D CNN to classify video frames independently and average the predictions. On the contrary, this is a very strong baseline for video classification.</p><div class="img-wrapper"><img src="/images/um-cv-2/18-1.png" width="50%" alt="Single-Frame CNN"><br> Fig: Single-Frame CNN</div><h3 id="late-fusion" tabindex="-1"><a class="header-anchor" href="#late-fusion"><span>Late Fusion</span></a></h3><ol><li>Single frame CNN + FC layers</li></ol><div class="img-wrapper"><img src="/images/um-cv-2/18-2.png" width="50%" alt="Late Fusion"><br> Fig: Late Fusion</div><ol start="2"><li>with pooling</li></ol><div class="img-wrapper"><img src="/images/um-cv-2/18-3.png" width="50%" alt="Late Fusion with Pooling"><br> Fig: Late Fusion with Pooling</div><p>Problem: Hard to compare low-level motion between frames.</p><h3 id="early-fusion" tabindex="-1"><a class="header-anchor" href="#early-fusion"><span>Early Fusion</span></a></h3><p><a href="https://ieeexplore.ieee.org/document/6909619" target="_blank" rel="noopener noreferrer">Large Scale Video Classification with Convolutional Neural Networks, CVPR 2014</a></p><div class="img-wrapper"><img src="/images/um-cv-2/18-4.png" width="50%" alt="Early Fusion"><br> Fig: Early Fusion</div><h3 id="_3d-cnn-slow-fusion" tabindex="-1"><a class="header-anchor" href="#_3d-cnn-slow-fusion"><span>3D CNN (Slow Fusion)</span></a></h3><p><a href="https://ieeexplore.ieee.org/document/6165309" target="_blank" rel="noopener noreferrer">Ji et al., 3D Convolutional Neural Networks for Human Action Recognition, TPAMI 2010</a></p><h3 id="comparison" tabindex="-1"><a class="header-anchor" href="#comparison"><span>Comparison</span></a></h3><div class="img-wrapper"><img src="/images/um-cv-2/18-5.png" width="65%" alt="Comparison"><br> Fig: Early Fusion vs Late Fusion vs 3D CNN</div><p>(In practice, we use much larger models than the ones shown in the figure above)</p><h4 id="_2d-conv-vs-3d-conv" tabindex="-1"><a class="header-anchor" href="#_2d-conv-vs-3d-conv"><span>2D Conv vs 3D Conv</span></a></h4><div class="img-wrapper"><img src="/images/um-cv-2/18-6.png" width="60%" alt="2D Conv vs 3D Conv"><br>Fig: 2D Conv vs 3D Conv</div><p>Problem: No temporal shift-invariance!</p><p>3D Conv filters are shift invariant since each filter slides over time.</p><p>Visualization of the first layer filters of a 3D temporal convnet: <a href="https://ieeexplore.ieee.org/document/6909619" target="_blank" rel="noopener noreferrer">Large-scale Video Classification with Convolutional Neural Networks, CVPR 2014</a></p><div class="img-wrapper"><img src="/images/um-cv-2/18-7.png" width="60%" alt="3D Conv Filters"><br>Fig: 3D Conv Filters</div><h4 id="example-video-dataset-sports-1m" tabindex="-1"><a class="header-anchor" href="#example-video-dataset-sports-1m"><span>Example Video Dataset: Sports-1M</span></a></h4><p>1M YouTube videos of sports events. 487 classes.</p><div class="img-wrapper"><img src="/images/um-cv-2/18-8.png" width="40%" alt="Sports-1M"><br>Fig: Sports-1M Top-5 Accuracy (in 2014)</div><p>Now 3D CNN architectures are much better.</p><h3 id="c3d-architecture" tabindex="-1"><a class="header-anchor" href="#c3d-architecture"><span>C3D Architecture</span></a></h3><p><a href="https://arxiv.org/abs/1412.0767" target="_blank" rel="noopener noreferrer">Tran et al., Learning Spatiotemporal Features with 3D Convolutional Networks, ICCV 2015</a></p><p>&quot;The VGG of 3D ConvNets&quot;</p><p>Problem: 3x3x3 conv is very computationally expensive.</p><ul><li>AlexNet: 0.7 GFLOP</li><li>VGG-16: 13.6 GFLOP</li><li>C3D: 39.5 GFLOP (2.9x VGG!)</li></ul><p>Insights: We need to treat time and space differently.</p><h2 id="two-stream-networks" tabindex="-1"><a class="header-anchor" href="#two-stream-networks"><span>Two-Stream Networks</span></a></h2><p><a href="https://link.springer.com/article/10.3758/BF03212378" target="_blank" rel="noopener noreferrer">Johansson, Visual Perception of Biological Motion and a Model for Its Analysis, Perception &amp; Psychophysics 1973</a></p><p>Human&#39;s brain is treating motion differently from static images. We do not need to see the pixels to recognize actions.</p><h3 id="optical-flow" tabindex="-1"><a class="header-anchor" href="#optical-flow"><span>Optical Flow</span></a></h3><p>Image at frame t and t+1: Optical flow is a 2D vector field that represents the motion of pixels between the two frames.</p><p>Two-Stream Networks: <a href="https://arxiv.org/abs/1406.2199" target="_blank" rel="noopener noreferrer">Simonyan and Zisserman, Two-Stream Convolutional Networks for Action Recognition in Videos, NIPS 2014</a></p><div class="img-wrapper"><img src="/images/um-cv-2/18-9.png" width="70%" alt="Two-Stream Networks"><br>Fig: Two-Stream Networks</div><p>At test time we take an average of the predictions of the two streams.</p><p><strong>Results</strong>(2014)</p><div class="img-wrapper"><img src="/images/um-cv-2/18-10.png" width="50%" alt="Two-Stream Networks Results"><br>Fig: Two-Stream Networks Results</div><h2 id="recurrent-structures" tabindex="-1"><a class="header-anchor" href="#recurrent-structures"><span>Recurrent Structures</span></a></h2><p>Use recurrent neural networks (RNNs) to model long-term temporal structure.</p><p>in 2011: way ahead of its time!</p><p><a href="https://link.springer.com/chapter/10.1007/978-3-642-25446-8_4" target="_blank" rel="noopener noreferrer">Baccouche et al, Sequential Deep Learning for Human Action Recognition, 2011</a></p><p><a href="https://arxiv.org/abs/1411.4389" target="_blank" rel="noopener noreferrer">Donahue et al, Long-term Recurrent Convolutional Networks for Visual Recognition and Description, CVPR 2015</a></p><p>We can use a similar structure to Multi-layer RNN to process videos.</p><p><a href="https://arxiv.org/abs/1511.06432" target="_blank" rel="noopener noreferrer">Ballas et al, Delving Deeper into Convolutional Networks for Learning Video, ICLR 2016</a></p><p>Recurrent CNN: Infinite temporal extent (convolutional)</p><p>Problem: RNNs are slow for long sequences.</p><h3 id="spatio-temporal-self-attention-nonlocal-block" tabindex="-1"><a class="header-anchor" href="#spatio-temporal-self-attention-nonlocal-block"><span>Spatio-Temporal Self Attention (Nonlocal Block)</span></a></h3><p><a href="https://arxiv.org/abs/1711.07971" target="_blank" rel="noopener noreferrer">Wang et al, Non-local Neural Networks, CVPR 2018</a></p><div class="img-wrapper"><img src="/images/um-cv-2/18-11.png" width="50%" alt="Nonlocal Block"><br>Fig: Nonlocal Block</div><h3 id="inflating-2d-networks-to-3d" tabindex="-1"><a class="header-anchor" href="#inflating-2d-networks-to-3d"><span>Inflating 2D Networks to 3D</span></a></h3><p><a href="https://arxiv.org/abs/1705.07750" target="_blank" rel="noopener noreferrer">Carreira and Zisserman, Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset, CVPR 2017</a></p><p>Inception-style architecture for 3D convnets.</p><p>Can use weights from 2D conv to initialize 3D conv: copy K_t times in Space and divide by K_t. This gives the same result as 2D conv given &quot;constant&quot; video input.</p><h3 id="weightlifting" tabindex="-1"><a class="header-anchor" href="#weightlifting"><span>Weightlifting</span></a></h3><p><a href="https://arxiv.org/abs/1611.02155" target="_blank" rel="noopener noreferrer">Feichtenhofer et al, Spatiotemporal Residual Networks for Video Action Recognition, CVPR 2018</a></p><div class="img-wrapper"><img src="/images/um-cv-2/18-12.png" width="50%" alt="Weightlifting"><br>Fig: Weightlifting</div><h2 id="treating-time-and-space-differently-slowfast-networks" tabindex="-1"><a class="header-anchor" href="#treating-time-and-space-differently-slowfast-networks"><span>Treating time and space differently: SlowFast Networks</span></a></h2><p><a href="https://arxiv.org/abs/1812.03982" target="_blank" rel="noopener noreferrer">Feichtenhofer et al, SlowFast Networks for Video Recognition, ICCV 2019</a></p><div class="img-wrapper"><img src="/images/um-cv-2/18-13.png" width="50%" alt="SlowFast Networks"><br>Fig: SlowFast Networks</div><h2 id="other-task-spatial-temporal-detection" tabindex="-1"><a class="header-anchor" href="#other-task-spatial-temporal-detection"><span>Other task: Spatial-Temporal Detection</span></a></h2><p>Given a long untrimmed video, detect all the people in space and time and classify the activities they are performing.</p><p>Some examples from AVA dataset:</p><p><a href="https://arxiv.org/abs/1705.08421" target="_blank" rel="noopener noreferrer">Gu et al, AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions, CVPR 2018</a></p><h2 id="notice-on-usage-and-attribution" tabindex="-1"><a class="header-anchor" href="#notice-on-usage-and-attribution"><span><strong>Notice on Usage and Attribution</strong></span></a></h2><p>This note is based on the <strong>University of Michigan&#39;s publicly available course EECS 498.008 / 598.008</strong> and is intended <strong>solely for personal learning and academic discussion</strong>, with no commercial use.</p><ul><li><strong>Nature of the Notes:</strong> These notes include extensive references and citations from course materials to ensure clarity and completeness. However, they are presented as personal interpretations and summaries, not as substitutes for the original course content.</li><li><strong>Original Course Resources:</strong> Please refer to the official <a href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/" target="_blank" rel="noopener noreferrer"><strong>University of Michigan website</strong></a> for complete and accurate course materials.</li><li><strong>Third-Party Open Access Content:</strong> This note may reference Open Access (OA) papers or resources cited within the course materials. These materials are used under their original Open Access licenses (e.g., CC BY, CC BY-SA).</li><li><strong>Proper Attribution:</strong> Every referenced OA resource is appropriately cited, including the author, publication title, source link, and license type.</li><li><strong>Copyright Notice:</strong> All rights to third-party content remain with their respective authors or publishers.</li><li><strong>Content Removal:</strong> If you believe any content infringes on your copyright, please contact me, and I will promptly remove the content in question.</li></ul><p>Thanks to the <strong>University of Michigan</strong> and the contributors to the course for their openness and dedication to accessible education.</p></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-380c246c data-v-7bfa3324><!--[--><!--]--><div class="edit-info" data-v-7bfa3324><div class="edit-link" data-v-7bfa3324><a class="vp-link link no-icon edit-link-button" href="https://github.com/SaturnTsen/saturntsen.github.io/edit/main/docs/notes/UM-CV/UM-CV 18 Videos.md" target="_blank" rel="noreferrer" data-v-7bfa3324><!--[--><span class="vpi-square-pen edit-link-icon" aria-label="edit icon" data-v-7bfa3324></span> Edit this page<!--]--><!----></a></div><!----></div><div class="contributors" aria-label="Contributors" data-v-7bfa3324><span class="contributors-label" data-v-7bfa3324>Contributors: </span><span class="contributors-info" data-v-7bfa3324><!--[--><!--[--><span class="contributor" data-v-7bfa3324>SaturnTsen</span><!----><!--]--><!--]--></span></div><nav class="prev-next" data-v-7bfa3324><div class="pager" data-v-7bfa3324><a class="vp-link link pager-link prev" href="/notes/um-cv/um-cv-17/" data-v-7bfa3324><!--[--><span class="desc" data-v-7bfa3324>Previous page</span><span class="title" data-v-7bfa3324>17 3D Vision</span><!--]--><!----></a></div><div class="pager" data-v-7bfa3324><a class="vp-link link pager-link next" href="/notes/um-cv/um-cv-19/" data-v-7bfa3324><!--[--><span class="desc" data-v-7bfa3324>Next page</span><span class="title" data-v-7bfa3324>19 Autoregressive Models, Variational Autoencoders</span><!--]--><!----></a></div></nav></footer><div id="comment" class="giscus-wrapper input-top vp-comment" vp-comment style="display:block;" data-v-380c246c><div style="display: flex;align-items: center;justify-content: center;height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);--icon-size: 48px;display: inline-block;width: var(--icon-size);height: var(--icon-size);background-color: currentcolor;-webkit-mask-image: var(--loading-icon);mask-image: var(--loading-icon)"></span></div></div><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-a218b6db data-v-6955073a><span class="percent" data-allow-mismatch data-v-6955073a>0%</span><span class="show icon vpi-back-to-top" data-v-6955073a></span><svg aria-hidden="true" data-v-6955073a><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-6955073a></circle></svg></button><footer class="vp-footer has-sidebar" vp-footer data-v-a218b6db data-v-d9d63044><!--[--><div class="container" data-v-d9d63044><p class="message" data-v-d9d63044>Powered by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://theme-plume.vuejs.press">vuepress-theme-plume</a></p><p class="copyright" data-v-d9d63044>© 2024 SaturnTsen | Powered by <a href="https://vuepress.vuejs.org/" target="_blank">VuePress</a> & <a href="https://theme-plume.vuejs.press/" target="_blank">Plume</a></p></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-BPmJL-vo.js" defer></script></body></html>